{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPU_optimization_example.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "zLl9oP-RfrdI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Setup of the OS**\n",
        "``\n",
        "''!'' in notebook means that you are executing commands in commad shell\n",
        "\n",
        "Update all packages of debian-based distributive of the Linux OS."
      ]
    },
    {
      "metadata": {
        "id": "7mFTn3l7fOLn",
        "colab_type": "code",
        "outputId": "7ab365f9-083c-4fe9-9b50-4ea6bcbbf9bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "! lsb_release -a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No LSB modules are available.\n",
            "Distributor ID:\tUbuntu\n",
            "Description:\tUbuntu 18.04.2 LTS\n",
            "Release:\t18.04\n",
            "Codename:\tbionic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OWOrJHDJaiYF",
        "colab_type": "code",
        "outputId": "3795d81c-3290-4062-ec9f-a61467f3f3c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!apt update -qq;"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VCA-ZzUJhSLv",
        "colab_type": "code",
        "outputId": "6dab25f8-840c-43bd-9388-dc4fbc594a51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        }
      },
      "cell_type": "code",
      "source": [
        "! apt list --upgradable"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rListing... 0%\r\rListing... 0%\r\rListing... 0%\r\rListing... Done\r\n",
            "\u001b[32mdefault-jre\u001b[0m/bionic-updates,bionic-security 2:1.11-68ubuntu1~18.04.1 amd64 [upgradable from: 2:1.10-63ubuntu1~02]\n",
            "\u001b[32mdefault-jre-headless\u001b[0m/bionic-updates,bionic-security 2:1.11-68ubuntu1~18.04.1 amd64 [upgradable from: 2:1.10-63ubuntu1~02]\n",
            "\u001b[32mdistro-info-data\u001b[0m/bionic-updates 0.37ubuntu0.4 all [upgradable from: 0.37ubuntu0.3]\n",
            "\u001b[32mjava-common\u001b[0m/bionic-updates,bionic-security 0.68ubuntu1~18.04.1 all [upgradable from: 0.63ubuntu1~02]\n",
            "\u001b[32mkeyboard-configuration\u001b[0m/bionic-updates 1.178ubuntu2.8 all [upgradable from: 1.178ubuntu2.7]\n",
            "\u001b[32mlibcudnn7\u001b[0m/unknown 7.5.0.56-1+cuda10.1 amd64 [upgradable from: 7.5.0.56-1+cuda10.0]\n",
            "\u001b[32mlibcudnn7-dev\u001b[0m/unknown 7.5.0.56-1+cuda10.1 amd64 [upgradable from: 7.5.0.56-1+cuda10.0]\n",
            "\u001b[32mlibidn11\u001b[0m/bionic-updates 1.33-2.1ubuntu1.2 amd64 [upgradable from: 1.33-2.1ubuntu1.1]\n",
            "\u001b[32mlibnccl-dev\u001b[0m/unknown 2.4.2-1+cuda10.1 amd64 [upgradable from: 2.4.2-1+cuda10.0]\n",
            "\u001b[32mlibnccl2\u001b[0m/unknown 2.4.2-1+cuda10.1 amd64 [upgradable from: 2.4.2-1+cuda10.0]\n",
            "\u001b[32mlibpam-systemd\u001b[0m/bionic-updates 237-3ubuntu10.20 amd64 [upgradable from: 237-3ubuntu10.17]\n",
            "\u001b[32mlibseccomp2\u001b[0m/bionic-updates 2.3.1-2.1ubuntu4.1 amd64 [upgradable from: 2.3.1-2.1ubuntu4]\n",
            "\u001b[32mlibsystemd0\u001b[0m/bionic-updates 237-3ubuntu10.20 amd64 [upgradable from: 237-3ubuntu10.17]\n",
            "\u001b[32mlibudev1\u001b[0m/bionic-updates 237-3ubuntu10.20 amd64 [upgradable from: 237-3ubuntu10.17]\n",
            "\u001b[32mlibunistring2\u001b[0m/bionic-updates 0.9.9-0ubuntu2 amd64 [upgradable from: 0.9.9-0ubuntu1]\n",
            "\u001b[32mlibxslt1.1\u001b[0m/bionic-updates,bionic-security 1.1.29-5ubuntu0.1 amd64 [upgradable from: 1.1.29-5]\n",
            "\u001b[32mopenjdk-11-jre\u001b[0m/bionic-updates,bionic-security 11.0.2+9-3ubuntu1~18.04.3 amd64 [upgradable from: 10.0.2+13-1ubuntu0.18.04.4]\n",
            "\u001b[32mopenjdk-11-jre-headless\u001b[0m/bionic-updates,bionic-security 11.0.2+9-3ubuntu1~18.04.3 amd64 [upgradable from: 10.0.2+13-1ubuntu0.18.04.4]\n",
            "\u001b[32mr-cran-backports\u001b[0m/bionic 1.1.4-1cran1ppabionic0 amd64 [upgradable from: 1.1.3-1cran1ppabionic0]\n",
            "\u001b[32mr-cran-broom\u001b[0m/bionic 0.5.2-1cran1ppabionic0 all [upgradable from: 0.5.1-1cran1ppabionic0]\n",
            "\u001b[32mr-cran-cluster\u001b[0m/bionic-cran35 2.0.8-1bionic0 amd64 [upgradable from: 2.0.7-1-1cranBionic0]\n",
            "\u001b[32mr-cran-devtools\u001b[0m/bionic 2.0.2-1cran1ppabionic0 all [upgradable from: 2.0.1-1cran1ppabionic0]\n",
            "\u001b[32mr-cran-gdtools\u001b[0m/bionic 0.1.8-1cran1ppabionic0 amd64 [upgradable from: 0.1.7-3cran1ppa0bionic0]\n",
            "\u001b[32mr-cran-ggplot2\u001b[0m/bionic 3.1.1-1cran1ppabionic0 all [upgradable from: 3.1.0-1cran1ppabionic0]\n",
            "\u001b[32mr-cran-mass\u001b[0m/bionic 7.3-51.3-1cran1ppabionic0 amd64 [upgradable from: 7.3-51.1-1cran1ppabionic0]\n",
            "\u001b[32mr-cran-nlme\u001b[0m/bionic 3.1.139-1ppabionic0 amd64 [upgradable from: 3.1.137-1cranBionic0]\n",
            "\u001b[32mr-cran-remotes\u001b[0m/bionic 2.0.4-1cran1ppabionic0 all [upgradable from: 2.0.2-1cran1ppabionic0]\n",
            "\u001b[32mr-cran-rlang\u001b[0m/bionic 0.3.4-1cran1ppabionic0 amd64 [upgradable from: 0.3.3-1cran1ppabionic0]\n",
            "\u001b[32mr-cran-rpart\u001b[0m/bionic 4.1-15-1cran1ppabionic0 amd64 [upgradable from: 4.1-13-1cranBionic0]\n",
            "\u001b[32mr-cran-rvest\u001b[0m/bionic 0.3.3-1cran1ppabionic0 all [upgradable from: 0.3.2-3cran2ppa0bionic0]\n",
            "\u001b[32mr-cran-survival\u001b[0m/bionic 2.44-1.1-1cran1ppabionic0 amd64 [upgradable from: 2.43-3-1cran1ppabionic0]\n",
            "\u001b[32mr-cran-tinytex\u001b[0m/bionic 0.12-1cran1ppabionic0 all [upgradable from: 0.11-1cran1ppabionic0]\n",
            "\u001b[32mr-cran-usethis\u001b[0m/bionic 1.5.0-1cran1ppabionic0 all [upgradable from: 1.4.0-1cran1ppabionic0]\n",
            "\u001b[32mr-cran-xfun\u001b[0m/bionic 0.6-1cran1ppabionic0 all [upgradable from: 0.5-1cran1ppabionic0]\n",
            "\u001b[32msystemd\u001b[0m/bionic-updates 237-3ubuntu10.20 amd64 [upgradable from: 237-3ubuntu10.17]\n",
            "\u001b[32msystemd-sysv\u001b[0m/bionic-updates 237-3ubuntu10.20 amd64 [upgradable from: 237-3ubuntu10.17]\n",
            "\u001b[32mudev\u001b[0m/bionic-updates 237-3ubuntu10.20 amd64 [upgradable from: 237-3ubuntu10.17]\n",
            "\u001b[32mwget\u001b[0m/bionic-updates,bionic-security 1.19.4-1ubuntu2.2 amd64 [upgradable from: 1.19.4-1ubuntu2.1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r-PVa1p_fpb-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Download package with repository parameters "
      ]
    },
    {
      "metadata": {
        "id": "DDGMeWNyg5Oz",
        "colab_type": "code",
        "outputId": "ec8c6cd8-bc32-4ed4-dcec-1e0c96af9868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb;"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-20 09:47:04--  https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb\n",
            "Resolving developer.nvidia.com (developer.nvidia.com)... 192.229.189.146\n",
            "Connecting to developer.nvidia.com (developer.nvidia.com)|192.229.189.146|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://developer.download.nvidia.com/compute/cuda/8.0/secure/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64.deb?TwB2qoLI-ZjF_gDQ6eu4ID4az96-lyC0-LdzrftTg5Sfzouy-8hSTTPfhsyFuA9Xqcuw9X3tzFqm0-q4kbm2fJ-wgNhznQ3j0HhPhPzjbuda3YFIvIP2KxRQGLHYl7foWCRHPFJPUWCSZNLQQ9Ofqd8QOVYLff4iI4_shDhITJJjdSeP0F5VKXF5U5p6YqC8I5HNPVTwPchLqqaRLFlAYd9jig [following]\n",
            "--2019-04-20 09:47:06--  https://developer.download.nvidia.com/compute/cuda/8.0/secure/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64.deb?TwB2qoLI-ZjF_gDQ6eu4ID4az96-lyC0-LdzrftTg5Sfzouy-8hSTTPfhsyFuA9Xqcuw9X3tzFqm0-q4kbm2fJ-wgNhznQ3j0HhPhPzjbuda3YFIvIP2KxRQGLHYl7foWCRHPFJPUWCSZNLQQ9Ofqd8QOVYLff4iI4_shDhITJJjdSeP0F5VKXF5U5p6YqC8I5HNPVTwPchLqqaRLFlAYd9jig\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 192.229.232.112, 2606:2800:247:2063:46e:21d:825:102e\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|192.229.232.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1913589814 (1.8G) [application/x-deb]\n",
            "Saving to: â€˜cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb.2â€™\n",
            "\n",
            "cuda-repo-ubuntu160 100%[===================>]   1.78G   127MB/s    in 13s     \n",
            "\n",
            "2019-04-20 09:47:18 (144 MB/s) - â€˜cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb.2â€™ saved [1913589814/1913589814]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uHRTu5w5iOjC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Installing CUDA repo details"
      ]
    },
    {
      "metadata": {
        "id": "237icJriiEEL",
        "colab_type": "code",
        "outputId": "d06ad252-4870-4e5f-92cb-116841c4c9e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "cell_type": "code",
      "source": [
        "!dpkg -i cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb;"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 132398 files and directories currently installed.)\n",
            "Preparing to unpack cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb ...\n",
            "Unpacking cuda-repo-ubuntu1604-8-0-local-ga2 (8.0.61-1) over (8.0.61-1) ...\n",
            "Setting up cuda-repo-ubuntu1604-8-0-local-ga2 (8.0.61-1) ...\n",
            "Warning: The postinst maintainerscript of the package cuda-repo-ubuntu1604-8-0-local-ga2\n",
            "Warning: seems to use apt-key (provided by apt) without depending on gnupg or gnupg2.\n",
            "Warning: This will BREAK in the future and should be fixed by the package maintainer(s).\n",
            "Note: Check first if apt-key functionality is needed at all - it probably isn't!\n",
            "Warning: apt-key should not be used in scripts (called from postinst maintainerscript of the package cuda-repo-ubuntu1604-8-0-local-ga2)\n",
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g1YDAmT3iZJT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Adding public key to access repository"
      ]
    },
    {
      "metadata": {
        "id": "e446iPSkijLJ",
        "colab_type": "code",
        "outputId": "61c0b604-4447-4cd5-a47f-926c9617ff2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-key add /var/cuda-repo-8-0-local-ga2/7fa2af80.pub;"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YN4z4TksiuuN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Update packages again, with new added repository"
      ]
    },
    {
      "metadata": {
        "id": "EWj-8posi2qP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get update -qq;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iRK0Putwk1xo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now check what versions of CUDA packages do we have.\n",
        "We search for **cuda-10-0 **"
      ]
    },
    {
      "metadata": {
        "id": "aOPXP2ajk9Ny",
        "colab_type": "code",
        "outputId": "eb737b3d-76d0-4fff-aef4-3d1be8191082",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3629
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-cache search cuda"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "libcuda1-340 - NVIDIA CUDA runtime library\n",
            "libnvidia-compute-390 - NVIDIA libcompute package\n",
            "boinc-client-nvidia-cuda - metapackage for CUDA-savvy BOINC client and manager\n",
            "caffe-cuda - Fast, open framework for Deep Learning (Meta)\n",
            "caffe-tools-cuda - Tools for fast, open framework for Deep Learning (CUDA)\n",
            "libcaffe-cuda-dev - development files for Caffe (CUDA)\n",
            "libcaffe-cuda1 - library of Caffe, deep leanring framework (CUDA)\n",
            "libcuda1-331 - Transitional package for libcuda1-340\n",
            "libcuda1-331-updates - Transitional package for libcuda1-340\n",
            "libcuda1-340-updates - Transitional package for libcuda1-340\n",
            "libcuda1-346 - Transitional package for libcuda1-352\n",
            "libcuda1-346-updates - Transitional package for libcuda1-352-updates\n",
            "libcuda1-361 - Transitional package for libcuda1-367\n",
            "libcuda1-367 - Transitional package for libcuda1-375\n",
            "libcuda1-375 - Transitional package for libcuda1-384\n",
            "libcudart9.1 - NVIDIA CUDA Runtime Library\n",
            "libcupti-dev - NVIDIA CUDA Profiler Tools Interface development files\n",
            "libcupti-doc - NVIDIA CUDA Profiler Tools Interface documentation\n",
            "libcupti9.1 - NVIDIA CUDA Profiler Tools Interface runtime library\n",
            "libnvrtc9.1 - CUDA Runtime Compilation (NVIDIA NVRTC Library)\n",
            "nvidia-cuda-dev - NVIDIA CUDA development files\n",
            "nvidia-cuda-doc - NVIDIA CUDA and OpenCL documentation\n",
            "nvidia-cuda-gdb - NVIDIA CUDA Debugger (GDB)\n",
            "nvidia-cuda-toolkit - NVIDIA CUDA development toolkit\n",
            "nvidia-profiler - NVIDIA Profiler for CUDA and OpenCL\n",
            "nvidia-visual-profiler - NVIDIA Visual Profiler for CUDA and OpenCL\n",
            "python-pycuda - Python module to access Nvidiaâ€˜s CUDA parallel computation API\n",
            "python-pycuda-dbg - Python module to access Nvidiaâ€˜s CUDA API (debug extensions)\n",
            "python-pycuda-doc - module to access Nvidiaâ€˜s CUDA computation API (documentation)\n",
            "python3-caffe-cuda - Python3 interface of Caffe (CUDA)\n",
            "python3-pycuda - Python 3 module to access Nvidiaâ€˜s CUDA parallel computation API\n",
            "python3-pycuda-dbg - Python 3 module to access Nvidiaâ€˜s CUDA API (debug extensions)\n",
            "cuda-cublas-dev-8-0 - CUBLAS native dev links, headers\n",
            "cuda-npp-8-0 - NPP native runtime libraries\n",
            "libcuda1-361-updates - Transitional package for libcuda1-375\n",
            "cuda-nvgraph-8-0 - NVGRAPH native runtime libraries\n",
            "cuda-nvgraph-dev-8-0 - NVGRAPH native dev links, headers\n",
            "cuda-command-line-tools-8-0 - CUDA command-line tools\n",
            "cuda-visual-tools-8-0 - CUDA visual tools\n",
            "cuda-demo-suite-8-0 - Demo suite for CUDA\n",
            "cuda-cudart-dev-8-0 - CUDA Runtime native dev links, headers\n",
            "cuda-drivers - CUDA Driver meta-package\n",
            "cuda-samples-8-0 - CUDA example applications\n",
            "cuda-runtime-8-0 - CUDA Runtime 8.0 meta-package\n",
            "cuda-minimal-build-8-0 - Minimal CUDA 8.0 toolkit build packages.\n",
            "cuda-cross-ppc64el-8-0 - CUDA 8.0 cross-platform meta-package\n",
            "cuda-curand-dev-8-0 - CURAND native dev links, headers\n",
            "cuda-toolkit-8-0 - CUDA Toolkit 8.0 meta-package\n",
            "cuda-cufft-8-0 - CUFFT native runtime libraries\n",
            "libcuda1-352 - Transitional package for libcuda1-375\n",
            "cuda-documentation-8-0 - CUDA documentation\n",
            "cuda-cusolver-8-0 - CUDA solver native runtime libraries\n",
            "cuda-cublas-8-0 - CUBLAS native runtime libraries\n",
            "cuda-curand-8-0 - CURAND native runtime libraries\n",
            "cuda-cusolver-dev-8-0 - CUDA solver native dev links, headers\n",
            "cuda-cross-aarch64-8-0 - CUDA 8.0 cross-platform meta-package\n",
            "cuda-8-0 - CUDA 8.0 meta-package\n",
            "cuda-cross-ppc64el - CUDA cross-platform meta-package\n",
            "cuda-nvml-dev-8-0 - NVML native dev links, headers\n",
            "cuda-cross-armhf-8-0 - CUDA 8.0 cross-platform meta-package\n",
            "cuda-nvrtc-dev-8-0 - NVRTC native dev links, headers\n",
            "cuda-core-8-0 - CUDA core tools\n",
            "cuda-cusparse-8-0 - CUSPARSE native runtime libraries\n",
            "cuda-cross-aarch64 - CUDA cross-platform meta-package\n",
            "cuda-cufft-dev-8-0 - CUFFT native dev links, headers\n",
            "cuda-nvrtc-8-0 - NVRTC native runtime libraries\n",
            "cuda-misc-headers-8-0 - CUDA miscellaneous headers\n",
            "cuda-cudart-8-0 - CUDA Runtime native Libraries\n",
            "cuda-license-8-0 - CUDA licenses\n",
            "cuda-driver-dev-8-0 - CUDA Driver native dev stub library\n",
            "libcuda1-352-updates - Transitional package for libcuda1-375\n",
            "cuda-cusparse-dev-8-0 - CUSPARSE native dev links, headers\n",
            "cuda-npp-dev-8-0 - NPP native dev links, headers\n",
            "cuda - CUDA meta-package\n",
            "cuda-cross-armhf - CUDA cross-platform meta-package\n",
            "cuda-gdb-src-8-0 - Contains the source code for cuda-gdb\n",
            "cuda-10-0 - CUDA 10.0 meta-package\n",
            "cuda-cublas-dev-10-0 - CUBLAS native dev links, headers\n",
            "cuda-10-1 - CUDA 10.1 meta-package\n",
            "cuda-compat-10-0 - CUDA Compatibility Platform\n",
            "cuda-command-line-tools-10-0 - CUDA command-line tools\n",
            "cuda-command-line-tools-10-1 - CUDA command-line tools\n",
            "cuda-compat-10-1 - CUDA Compatibility Platform\n",
            "cuda-compiler-10-0 - CUDA compiler\n",
            "cuda-compiler-10-1 - CUDA compiler\n",
            "cuda-core-10-0 - CUDA core tools\n",
            "cuda-core-10-1 - CUDA core tools\n",
            "cuda-cross-qnx-10-0 - CUDA 10.0 cross-platform meta-package\n",
            "cuda-cross-qnx - CUDA cross-platform meta-package\n",
            "cuda-cublas-10-0 - CUBLAS native runtime libraries\n",
            "cuda-cudart-dev-10-0 - CUDA Runtime native dev links, headers\n",
            "cuda-cudart-10-0 - CUDA Runtime native Libraries\n",
            "cuda-cudart-10-1 - CUDA Runtime native Libraries\n",
            "cuda-cudart-dev-10-1 - CUDA Runtime native dev links, headers\n",
            "cuda-cufft-10-0 - CUFFT native runtime libraries\n",
            "cuda-cufft-10-1 - CUFFT native runtime libraries\n",
            "cuda-cufft-dev-10-0 - CUFFT native dev links, headers\n",
            "cuda-cufft-dev-10-1 - CUFFT native dev links, headers\n",
            "cuda-cuobjdump-10-0 - CUDA cuobjdump\n",
            "cuda-cuobjdump-10-1 - CUDA cuobjdump\n",
            "cuda-cupti-10-0 - CUDA profiling tools interface.\n",
            "cuda-cupti-10-1 - CUDA profiling tools interface.\n",
            "cuda-curand-10-0 - CURAND native runtime libraries\n",
            "cuda-curand-10-1 - CURAND native runtime libraries\n",
            "cuda-curand-dev-10-0 - CURAND native dev links, headers\n",
            "cuda-curand-dev-10-1 - CURAND native dev links, headers\n",
            "cuda-cusolver-10-0 - CUDA solver native runtime libraries\n",
            "cuda-cusolver-10-1 - CUDA solver native runtime libraries\n",
            "cuda-cusolver-dev-10-0 - CUDA solver native dev links, headers\n",
            "cuda-cusolver-dev-10-1 - CUDA solver native dev links, headers\n",
            "cuda-cusparse-10-0 - CUSPARSE native runtime libraries\n",
            "cuda-cusparse-10-1 - CUSPARSE native runtime libraries\n",
            "cuda-cusparse-dev-10-0 - CUSPARSE native dev links, headers\n",
            "cuda-cusparse-dev-10-1 - CUSPARSE native dev links, headers\n",
            "cuda-demo-suite-10-0 - Demo suite for CUDA\n",
            "cuda-demo-suite-10-1 - Demo suite for CUDA\n",
            "cuda-documentation-10-0 - CUDA documentation\n",
            "cuda-documentation-10-1 - CUDA documentation\n",
            "cuda-driver-dev-10-0 - CUDA Driver native dev stub library\n",
            "cuda-driver-dev-10-1 - CUDA Driver native dev stub library\n",
            "cuda-drivers-diagnostic - CUDA Driver diagnostics meta-package\n",
            "cuda-gdb-10-0 - CUDA-GDB\n",
            "cuda-gdb-10-1 - CUDA-GDB\n",
            "cuda-gdb-src-10-0 - Contains the source code for cuda-gdb\n",
            "cuda-gdb-src-10-1 - Contains the source code for cuda-gdb\n",
            "cuda-gpu-library-advisor-10-0 - CUDA GPU Library Advisor.\n",
            "cuda-gpu-library-advisor-10-1 - CUDA GPU Library Advisor.\n",
            "cuda-libraries-10-0 - CUDA Libraries 10.0 meta-package\n",
            "cuda-libraries-10-1 - CUDA Libraries 10.1 meta-package\n",
            "cuda-libraries-dev-10-0 - CUDA Libraries 10.0 development meta-package\n",
            "cuda-libraries-dev-10-1 - CUDA Libraries 10.1 development meta-package\n",
            "cuda-license-10-0 - CUDA licenses\n",
            "cuda-license-10-1 - CUDA licenses\n",
            "cuda-memcheck-10-0 - CUDA-MEMCHECK\n",
            "cuda-memcheck-10-1 - CUDA-MEMCHECK\n",
            "cuda-minimal-build-10-0 - Minimal CUDA 10.0 toolkit build packages.\n",
            "cuda-minimal-build-10-1 - Minimal CUDA 10.1 toolkit build packages.\n",
            "cuda-misc-headers-10-0 - CUDA miscellaneous headers\n",
            "cuda-misc-headers-10-1 - CUDA miscellaneous headers\n",
            "cuda-npp-10-0 - NPP native runtime libraries\n",
            "cuda-npp-10-1 - NPP native runtime libraries\n",
            "cuda-npp-dev-10-0 - NPP native dev links, headers\n",
            "cuda-npp-dev-10-1 - NPP native dev links, headers\n",
            "cuda-nsight-10-0 - CUDA nsight\n",
            "cuda-nsight-10-1 - CUDA nsight\n",
            "cuda-nsight-compute--10-0 - NVIDIA Nsight Compute Addon\n",
            "cuda-nsight-compute-10-0 - NVIDIA Nsight Compute\n",
            "cuda-nsight-compute-10-1 - NVIDIA Nsight Compute\n",
            "cuda-nsight-systems-10-1 - NVIDIA Nsight Systems\n",
            "cuda-nvcc-10-0 - CUDA nvcc\n",
            "cuda-nvcc-10-1 - CUDA nvcc\n",
            "cuda-nvdisasm-10-0 - CUDA disassembler\n",
            "cuda-nvdisasm-10-1 - CUDA disassembler\n",
            "cuda-nvgraph-10-0 - NVGRAPH native runtime libraries\n",
            "cuda-nvgraph-10-1 - NVGRAPH native runtime libraries\n",
            "cuda-nvgraph-dev-10-0 - NVGRAPH native dev links, headers\n",
            "cuda-nvgraph-dev-10-1 - NVGRAPH native dev links, headers\n",
            "cuda-nvjpeg-10-0 - NVJPEG native runtime libraries\n",
            "cuda-nvjpeg-10-1 - NVJPEG native runtime libraries\n",
            "cuda-nvjpeg-dev-10-0 - NVJPEG native dev links, headers\n",
            "cuda-nvjpeg-dev-10-1 - NVJPEG native dev links, headers\n",
            "cuda-nvml-dev-10-0 - NVML native dev links, headers\n",
            "cuda-nvml-dev-10-1 - NVML native dev links, headers\n",
            "cuda-nvprof-10-0 - CUDA Profiler tools\n",
            "cuda-nvprof-10-1 - CUDA Profiler tools\n",
            "cuda-nvprune-10-0 - CUDA nvprune\n",
            "cuda-nvprune-10-1 - CUDA nvprune\n",
            "cuda-nvrtc-10-0 - NVRTC native runtime libraries\n",
            "cuda-nvrtc-10-1 - NVRTC native runtime libraries\n",
            "cuda-nvrtc-dev-10-0 - NVRTC native dev links, headers\n",
            "cuda-nvrtc-dev-10-1 - NVRTC native dev links, headers\n",
            "cuda-nvtx-10-0 - NVIDIA Tools Extension\n",
            "cuda-nvtx-10-1 - NVIDIA Tools Extension\n",
            "cuda-nvvp-10-0 - CUDA nvvp\n",
            "cuda-nvvp-10-1 - CUDA nvvp\n",
            "cuda-repo-ubuntu1804 - cuda repository configuration files\n",
            "cuda-runtime-10-0 - CUDA Runtime 10.0 meta-package\n",
            "cuda-runtime-10-1 - CUDA Runtime 10.1 meta-package\n",
            "cuda-samples-10-0 - CUDA example applications\n",
            "cuda-samples-10-1 - CUDA example applications\n",
            "cuda-sanitizer-api-10-1 - CUDA Sanitizer API\n",
            "cuda-toolkit-10-0 - CUDA Toolkit 10.0 meta-package\n",
            "cuda-toolkit-10-1 - CUDA Toolkit 10.1 meta-package\n",
            "cuda-tools-10-0 - CUDA Tools meta-package\n",
            "cuda-tools-10-1 - CUDA Tools meta-package\n",
            "cuda-visual-tools-10-0 - CUDA visual tools\n",
            "cuda-visual-tools-10-1 - CUDA visual tools\n",
            "libcuda1-384 - Transitional package for nvidia-headless-418\n",
            "libnvidia-compute-410 - NVIDIA libcompute package\n",
            "libnvidia-compute-418 - NVIDIA libcompute package\n",
            "libnvidia-decode-410 - NVIDIA Video Decoding runtime libraries\n",
            "libnvidia-decode-418 - NVIDIA Video Decoding runtime libraries\n",
            "nvidia-compute-utils-410 - NVIDIA compute utilities\n",
            "nvidia-compute-utils-418 - NVIDIA compute utilities\n",
            "nvidia-headless-410 - NVIDIA headless metapackage\n",
            "nvidia-headless-418 - NVIDIA headless metapackage\n",
            "nvidia-headless-no-dkms-410 - NVIDIA headless metapackage - no DKMS\n",
            "nvidia-headless-no-dkms-418 - NVIDIA headless metapackage - no DKMS\n",
            "libcuda1-304 - NVIDIA CUDA runtime library\n",
            "libcuda1-304-updates - Transitional package for libcuda1-304\n",
            "libcuda1-387 - Transitional package for nvidia-compute-390\n",
            "libcuda1-390 - Transitional package for nvidia-compute-390\n",
            "libnvidia-compute-396 - NVIDIA libcompute package\n",
            "libnvidia-compute-415 - NVIDIA libcompute package\n",
            "r-cran-cudabayesregdata - GNU R package \"Data sets for the examples used in the\n",
            "nvinfer-runtime-trt-repo-ubuntu1804-5.0.0-rc-cuda10.0 - nvinfer-runtime-trt repository configuration files\n",
            "nvinfer-runtime-trt-repo-ubuntu1804-5.0.2-ga-cuda10.0 - nvinfer-runtime-trt repository configuration files\n",
            "cuda-repo-ubuntu1604-8-0-local-ga2 - cuda repository configuration files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J5iJMpgXi7Hu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Install packages for CUDA programming with C++"
      ]
    },
    {
      "metadata": {
        "id": "VovJ51TCjB09",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install cuda-10-0 gcc-5 g++-5 -y -qq;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6kk8rplbk0jS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create symbolic links  for compiler files"
      ]
    },
    {
      "metadata": {
        "id": "TpWdZVLolBdj",
        "colab_type": "code",
        "outputId": "b8cc02e9-9773-4da1-dad4-8ca333854b56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "!ln -s /usr/bin/gcc-5 /usr/local/cuda/bin/gcc;\n",
        "!ln -s /usr/bin/g++-5 /usr/local/cuda/bin/g++;"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ln: failed to create symbolic link '/usr/local/cuda/bin/gcc': File exists\n",
            "ln: failed to create symbolic link '/usr/local/cuda/bin/g++': File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r_UMlVN1lHWB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check is NVCC up and running:\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "rORu2yChldl6",
        "colab_type": "code",
        "outputId": "3cf06f09-e66e-4fee-c711-22a7226a563d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1Neyi2-7li5c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Upload extension to notebook to work with CUDA C directly from notebook"
      ]
    },
    {
      "metadata": {
        "id": "gkQ3ksTWlpyM",
        "colab_type": "code",
        "outputId": "d3a60cf5-ee7f-41a6-fd78-3e8d9f2db632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-5ccehzfn\n",
            "Requirement already satisfied (use --upgrade to upgrade): NVCCPlugin==0.0.2 from git+git://github.com/andreinechaev/nvcc4jupyter.git in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-j2nwa3za/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7hgb-Mkwlq12",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load cuda extension to the notebook"
      ]
    },
    {
      "metadata": {
        "id": "Oa6pxLFilw89",
        "colab_type": "code",
        "outputId": "bb9b9c92-f597-469a-fd30-0a9d2a634fb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VdkAoLecl51d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check your GPU card\n",
        "\n",
        "For this we need explicitly say to the interpreter, that we want to use the extension by **adding %cu at the beginning of each cell with CUDA code.**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ILsqpyeioTyD",
        "colab_type": "code",
        "outputId": "d0760442-8e6e-488d-f1f7-7e82e1ae7b36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <iostream>\n",
        "#include <time.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "#define N  1024\n",
        "inline cudaError_t checkCudaErr(cudaError_t err, const char* msg) {\n",
        "  if (err != cudaSuccess) {\n",
        "    fprintf(stderr, \"CUDA Runtime error at %s: %s\\n\", msg, cudaGetErrorString(err));\n",
        "  }\n",
        "  return err;\n",
        "}\n",
        "__global__ void matrixMulGPU( int * a, int * b, int * c )\n",
        "{\n",
        "  /*\n",
        "   * Build out this kernel.\n",
        "   */\n",
        "    int row = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    int col = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    \n",
        "    int val = 0;\n",
        "    if (row < N && col < N) {\n",
        "      for (int i = 0; i < N; ++i) {\n",
        "         val += a[row * N + i] * b[i * N + col];\n",
        "       }\n",
        "    \n",
        "      c[row * N + col] = val;\n",
        "    }\n",
        "}\n",
        "/*\n",
        " * This CPU function already works, and will run to create a solution matrix\n",
        " * against which to verify your work building out the matrixMulGPU kernel.\n",
        " */\n",
        "void matrixMulCPU( int * a, int * b, int * c )\n",
        "{\n",
        "  int val = 0;\n",
        "for( int row = 0; row < N; ++row )\n",
        "    for( int col = 0; col < N; ++col )\n",
        "    {\n",
        "      val = 0;\n",
        "      for ( int k = 0; k < N; ++k )\n",
        "        val += a[row * N + k] * b[k * N + col];\n",
        "      c[row * N + col] = val;\n",
        "    }\n",
        "}\n",
        "int main()\n",
        "{\n",
        "  int *a, *b, *c_cpu, *c_gpu; // Allocate a solution matrix for both the CPU and the GPU operations\n",
        "int size = N * N * sizeof (int); // Number of bytes of an N x N matrix\n",
        "// Allocate memory\n",
        "  cudaMallocManaged (&a, size);\n",
        "  cudaMallocManaged (&b, size);\n",
        "  cudaMallocManaged (&c_cpu, size);\n",
        "  cudaMallocManaged (&c_gpu, size);\n",
        "// Initialize memory; create 2D matrices\n",
        "  for( int row = 0; row < N; ++row )\n",
        "    for( int col = 0; col < N; ++col )\n",
        "    {\n",
        "      a[row*N + col] = row;\n",
        "      b[row*N + col] = col+2;\n",
        "      c_cpu[row*N + col] = 0;\n",
        "      c_gpu[row*N + col] = 0;\n",
        "    }\n",
        "/*\n",
        "   * Assign `threads_per_block` and `number_of_blocks` 2D values\n",
        "   * that can be used in matrixMulGPU above.\n",
        "   */\n",
        "dim3 threads_per_block(32, 32, 1);\n",
        "  dim3 number_of_blocks(N / threads_per_block.x + 1, N / threads_per_block.y + 1, 1);\n",
        "    clock_t gpu_start = clock();\n",
        "matrixMulGPU <<< number_of_blocks, threads_per_block >>> ( a, b, c_gpu );\n",
        "    clock_t gpu_end = clock();\n",
        "checkCudaErr(cudaDeviceSynchronize(), \"Syncronization\");\n",
        "checkCudaErr(cudaGetLastError(), \"GPU\");\n",
        "// Call the CPU version to check our work\n",
        "    clock_t cpu_start = clock();\n",
        "  matrixMulCPU( a, b, c_cpu );\n",
        "    clock_t cpu_end = clock();\n",
        "// Compare the two answers to make sure they are equal\n",
        "  bool error = false;\n",
        "  for( int row = 0; row < N && !error; ++row )\n",
        "    for( int col = 0; col < N && !error; ++col )\n",
        "      if (c_cpu[row * N + col] != c_gpu[row * N + col])\n",
        "      {\n",
        "        printf(\"FOUND ERROR at c[%d][%d]\\n\", row, col);\n",
        "        error = true;\n",
        "        break;\n",
        "      }\n",
        "if (!error)\n",
        "    cout << \"Success! \";\n",
        "  cout << cpu_end - cpu_start << \" \" << gpu_end - gpu_start;\n",
        "// Free all our allocated memory\n",
        "  cudaFree(a); cudaFree(b);\n",
        "  cudaFree( c_cpu ); cudaFree( c_gpu );\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Success! 6506506 170'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "id": "3RXT_W1ToTSD",
        "colab_type": "code",
        "outputId": "95e267dd-4ffa-4e6e-a76f-e27f7167b4e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "!ls /usr/local/cuda/samples/1_Utilities/deviceQuery/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deviceQuery\t deviceQuery.o\tNsightEclipse.xml\n",
            "deviceQuery.cpp  Makefile\treadme.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cgmvM-38sS5W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Make sample from NVIDI sample directory"
      ]
    },
    {
      "metadata": {
        "id": "689gXnyarnth",
        "colab_type": "code",
        "outputId": "0d3bdd25-13a5-4322-a304-80bb5bb522e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "cell_type": "code",
      "source": [
        "!cd /usr/local/cuda/samples/1_Utilities/deviceQuery;make clean; make\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm -f deviceQuery deviceQuery.o\n",
            "rm -rf ../../bin/x86_64/linux/release/deviceQuery\n",
            "/usr/local/cuda-10.0/bin/nvcc -ccbin g++ -I../../common/inc  -m64    -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_75,code=compute_75 -o deviceQuery.o -c deviceQuery.cpp\n",
            "/usr/local/cuda-10.0/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_75,code=compute_75 -o deviceQuery deviceQuery.o \n",
            "mkdir -p ../../bin/x86_64/linux/release\n",
            "cp deviceQuery ../../bin/x86_64/linux/release\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MeFRMqJWsV_B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Run sample"
      ]
    },
    {
      "metadata": {
        "id": "nB_dBQvSsX_8",
        "colab_type": "code",
        "outputId": "00302427-57c1-4bba-cc5e-69f909d2d166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        }
      },
      "cell_type": "code",
      "source": [
        "! /usr/local/cuda/samples/1_Utilities/deviceQuery/deviceQuery"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/cuda/samples/1_Utilities/deviceQuery/deviceQuery Starting...\n",
            "\n",
            " CUDA Device Query (Runtime API) version (CUDART static linking)\n",
            "\n",
            "Detected 1 CUDA Capable device(s)\n",
            "\n",
            "Device 0: \"Tesla T4\"\n",
            "  CUDA Driver Version / Runtime Version          10.0 / 10.0\n",
            "  CUDA Capability Major/Minor version number:    7.5\n",
            "  Total amount of global memory:                 15080 MBytes (15812263936 bytes)\n",
            "  (40) Multiprocessors, ( 64) CUDA Cores/MP:     2560 CUDA Cores\n",
            "  GPU Max Clock rate:                            1590 MHz (1.59 GHz)\n",
            "  Memory Clock rate:                             5001 Mhz\n",
            "  Memory Bus Width:                              256-bit\n",
            "  L2 Cache Size:                                 4194304 bytes\n",
            "  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\n",
            "  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n",
            "  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n",
            "  Total amount of constant memory:               65536 bytes\n",
            "  Total amount of shared memory per block:       49152 bytes\n",
            "  Total number of registers available per block: 65536\n",
            "  Warp size:                                     32\n",
            "  Maximum number of threads per multiprocessor:  1024\n",
            "  Maximum number of threads per block:           1024\n",
            "  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n",
            "  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n",
            "  Maximum memory pitch:                          2147483647 bytes\n",
            "  Texture alignment:                             512 bytes\n",
            "  Concurrent copy and kernel execution:          Yes with 3 copy engine(s)\n",
            "  Run time limit on kernels:                     No\n",
            "  Integrated GPU sharing Host Memory:            No\n",
            "  Support host page-locked memory mapping:       Yes\n",
            "  Alignment requirement for Surfaces:            Yes\n",
            "  Device has ECC support:                        Enabled\n",
            "  Device supports Unified Addressing (UVA):      Yes\n",
            "  Device supports Compute Preemption:            Yes\n",
            "  Supports Cooperative Kernel Launch:            Yes\n",
            "  Supports MultiDevice Co-op Kernel Launch:      Yes\n",
            "  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 4\n",
            "  Compute Mode:\n",
            "     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n",
            "\n",
            "deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.0, CUDA Runtime Version = 10.0, NumDevs = 1\n",
            "Result = PASS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XOyyDeiysyXr",
        "colab_type": "code",
        "outputId": "c25c1ead-d262-4447-c6dd-28773c347fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Apr 20 09:48:16 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.56       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    15W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9mrRnS1Lsaq8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mount google drive with test image:"
      ]
    },
    {
      "metadata": {
        "id": "murDhIypsc_F",
        "colab_type": "code",
        "outputId": "ca196145-f2fc-4bc7-81b0-9060bdf3eb5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-Gbui9jyWoVC",
        "colab_type": "code",
        "outputId": "fd54fb1d-6c38-44f8-f2f2-f69994800594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -al '/content/drive/My Drive/samples'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 196\n",
            "-rw------- 1 root root 200651 Apr 20 07:56 800px-Kuh-Warnung.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UqNp8Qrctr7Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Code for SUM with 'REDUCE', simplify"
      ]
    },
    {
      "metadata": {
        "id": "vIDaCN0FtiM2",
        "colab_type": "code",
        "outputId": "b28652f7-1c7c-4e57-b658-08a3a42687b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <iostream>\n",
        "#include <time.h>\n",
        "#include <fstream>\n",
        "#include <stdint.h> \n",
        "\n",
        "#define BLOCK 1024\n",
        "\n",
        "#define cudaCheckErrors(msg) \\\n",
        "    do { \\\n",
        "        cudaError_t __err = cudaGetLastError(); \\\n",
        "        if (__err != cudaSuccess) { \\\n",
        "            fprintf(stderr, \"Fatal error at runtime: %s (%s at %s:%d)\\n\", \\\n",
        "                msg, cudaGetErrorString(__err), \\\n",
        "                __FILE__, __LINE__); \\\n",
        "            fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\\n",
        "            exit(1); \\\n",
        "        } \\\n",
        "    } while (0)\n",
        "\n",
        "__global__ void fill_1_block( unsigned char *vec )\n",
        "{    \n",
        "    int idx = threadIdx.x;\n",
        "    vec[idx] = 1;\n",
        "}\n",
        "\n",
        "__global__ void sum_reduce_simple(unsigned char *g_ivec,  int *g_ovec){\n",
        "    extern __shared__ int sdata[];\n",
        "    int idx = threadIdx.x;\n",
        "    sdata[idx] = g_ivec[idx];\n",
        "    for (unsigned int s=1; s <  blockDim.x ; s *= 2) {\n",
        "        if (idx % (2*s) == 0) {\n",
        "            sdata[idx] += sdata[idx + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    g_ovec[0] = sdata[0];\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "    cudaEvent_t start, stop;\n",
        "    float time;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    \n",
        "    unsigned char *d_image, *h_image;\n",
        "    int *d_result, *h_result ;\n",
        "         \n",
        "    size_t dszp = BLOCK;\n",
        "    \n",
        "    //ALLOCATE HOST MEM\n",
        "    h_image = (unsigned char*)malloc(dszp);\n",
        "    h_result = (int *) malloc(sizeof(int));\n",
        "    \n",
        "    //ALLOCATE MEM\n",
        "    cudaMalloc(&d_image, dszp);\n",
        "    cudaMalloc(&d_result, sizeof(int));\n",
        "    cudaCheckErrors(\"cudaMalloc fail \\n\");\n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "    //FILL VALUES\n",
        "    fill_1_block <<< 1, 1024 >>> (d_image);\n",
        "    cudaCheckErrors(\"Kernel CALL fail \\n\");\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    //printf (\"Time for the filling kernel: %f ms\\n\", time);\n",
        "    \n",
        "    cudaMemcpy(h_image, d_image, dszp*sizeof(unsigned char), cudaMemcpyDeviceToHost);\n",
        "\t  cudaCheckErrors(\"Memory copying filled image fail \\n\");\n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "    sum_reduce_simple <<< 1, 1024, 1024*sizeof(int) >>> (d_image, d_result);\n",
        "    cudaCheckErrors(\"Kernel sum_reduce_simple CALL fail \\n\");\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    printf (\"Time for the sum_reduce_simple kernel: %f ms\\n\", time);\n",
        "    \n",
        "    cudaMemcpy(h_result, d_result, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\t  cudaCheckErrors(\"Memory copying result fail \\n\");\n",
        "    \n",
        "    //FREE MEM\n",
        "    cudaFree(d_image);\n",
        "    cudaFree(d_result);\n",
        "    cudaCheckErrors(\"cudaFree fail \\n\");\n",
        "    \n",
        "    printf (\"SUM is: %d\\n\",h_result[0]);\n",
        "    printf (\"%u, %u ... %u, %u\\n\",h_image[0], h_image[1], h_image[1022], h_image[1023]);    \n",
        "    //printf (\"All is OK \");\n",
        "    \n",
        "    free(h_image);\n",
        "    free(h_result);\n",
        "    return(0);\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Time for the sum_reduce_simple kernel: 0.021120 ms\\nSUM is: 1024\\n1, 1 ... 1, 1\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "GAYxQCKuOIB1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Think about REDUCE**  1024 elements"
      ]
    },
    {
      "metadata": {
        "id": "n2gSl-dVNATN",
        "colab_type": "code",
        "outputId": "9d856102-1485-455b-d0a5-bb17050c7494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <iostream>\n",
        "#include <time.h>\n",
        "#include <fstream>\n",
        "#include <stdint.h> \n",
        "\n",
        "#define BLOCK 1024\n",
        "\n",
        "#define cudaCheckErrors(msg) \\\n",
        "    do { \\\n",
        "        cudaError_t __err = cudaGetLastError(); \\\n",
        "        if (__err != cudaSuccess) { \\\n",
        "            fprintf(stderr, \"Fatal error at runtime: %s (%s at %s:%d)\\n\", \\\n",
        "                msg, cudaGetErrorString(__err), \\\n",
        "                __FILE__, __LINE__); \\\n",
        "            fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\\n",
        "            exit(1); \\\n",
        "        } \\\n",
        "    } while (0)\n",
        "\n",
        "__global__ void fill_1_block( unsigned char *vec )\n",
        "{    \n",
        "    int idx = threadIdx.x;    \n",
        "    //how to make it random\n",
        "    vec[idx] = 1;    \n",
        "}\n",
        "\n",
        "__global__ void sum_reduce_simple(unsigned char *g_ivec,  int *g_ovec){\n",
        "    extern __shared__ int sdata[];\n",
        "    \n",
        "    //each thread load s one element from global to shared mem\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i =  blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    sdata[tid] = g_ivec[i];\n",
        "    __syncthreads();\n",
        "\n",
        "    // do reduction in shared mem\n",
        "    for (unsigned int s=1; s <  blockDim.x ; s *= 2) {\n",
        "        if (tid % (2*s) == 0) {\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_ovec[blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "    cudaEvent_t start, stop;\n",
        "    float time;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    \n",
        "    unsigned char *d_image, *h_image;\n",
        "    int *d_result, *h_result ;\n",
        "         \n",
        "    size_t dszp = BLOCK;\n",
        "    \n",
        "    //ALLOCATE HOST MEM\n",
        "    h_image = (unsigned char*)malloc(dszp);\n",
        "    h_result = (int*)malloc(1*sizeof(int));    \n",
        "    \n",
        "    //ALLOCATE MEM\n",
        "    cudaMalloc(&d_image, dszp);\n",
        "    cudaMalloc(&d_result, 1*sizeof(int));\n",
        "    cudaCheckErrors(\"cudaMalloc fail \\n\");\n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "    //FILL VALUES\n",
        "    fill_1_block <<< 1, 1024 >>> (d_image);\n",
        "    cudaCheckErrors(\"Kernel CALL fail \\n\");\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    //printf (\"Time for the filling kernel: %f ms\\n\", time);\n",
        "    \n",
        "    cudaMemcpy(h_image, d_image, dszp*sizeof(unsigned char), cudaMemcpyDeviceToHost);\n",
        "\t  cudaCheckErrors(\"Memory copying filled image fail \\n\");\n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "    sum_reduce_simple <<< 1, 1024, BLOCK*sizeof(int) >>> (d_image, d_result);\n",
        "    cudaCheckErrors(\"Kernel sum_reduce_simple CALL fail \\n\");\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    printf (\"Time for the sum_reduce_simple kernel: %f ms\\n\", time);\n",
        "    \n",
        "    cudaMemcpy(h_result, d_result, 1*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\t  cudaCheckErrors(\"Memory copying result fail \\n\");\n",
        "    \n",
        "    //FREE MEM\n",
        "    cudaFree(d_image);\n",
        "    cudaFree(d_result);\n",
        "    cudaCheckErrors(\"cudaFree fail \\n\");\n",
        "    \n",
        "    printf (\"SUM is: %d\\n\",h_result[0]);\n",
        "    //printf (\"%u, %u ... %u, %u\\n\",h_image[0], h_image[1], h_image[1022], h_image[1023]);    \n",
        "    //printf (\"All is OK \");\n",
        "    \n",
        "    free(h_image);\n",
        "    free(h_result);\n",
        "    return(0);\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Time for the sum_reduce_simple kernel: 0.021472 ms\\nSUM is: 1024\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "metadata": {
        "id": "PIOapn1wZ3B9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "MAKE REDUCE SUM for **1024X1024 (1MB)**"
      ]
    },
    {
      "metadata": {
        "id": "GjEV_-peaQUV",
        "colab_type": "code",
        "outputId": "2924b0bc-4fe2-4af7-a7cb-1914b26b3487",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <iostream>\n",
        "#include <time.h>\n",
        "#include <fstream>\n",
        "#include <stdint.h> \n",
        "\n",
        "#define BLOCK 1024\n",
        "\n",
        "#define cudaCheckErrors(msg) \\\n",
        "    do { \\\n",
        "        cudaError_t __err = cudaGetLastError(); \\\n",
        "        if (__err != cudaSuccess) { \\\n",
        "            fprintf(stderr, \"Fatal error at runtime: %s (%s at %s:%d)\\n\", \\\n",
        "                msg, cudaGetErrorString(__err), \\\n",
        "                __FILE__, __LINE__); \\\n",
        "            fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\\n",
        "            exit(1); \\\n",
        "        } \\\n",
        "    } while (0)\n",
        "\n",
        "__global__ void fill_1_block( unsigned char *vec )\n",
        "{    \n",
        "    int idx = threadIdx.x;    \n",
        "    unsigned int i =  blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    \n",
        "    //how to make it random?\n",
        "    vec[i] = 1;    \n",
        "}\n",
        "\n",
        "__global__ void sum_reduce_simple(unsigned char *g_ivec,  int *g_ovec){\n",
        "    extern __shared__ int sdata[];\n",
        "    \n",
        "    //each thread load s one element from global to shared mem\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i =  blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    sdata[tid] = g_ivec[i];\n",
        "    __syncthreads();\n",
        "\n",
        "    // do reduction in shared mem\n",
        "    for (unsigned int s=1; s <  blockDim.x ; s *= 2) {\n",
        "        if (tid % (2*s) == 0) {\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_ovec[blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "    cudaEvent_t start, stop;\n",
        "    float time;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    \n",
        "    unsigned char *d_image, *h_image;\n",
        "    int *d_result, *h_result ;\n",
        "         \n",
        "    size_t dszp = BLOCK*1024;\n",
        "    \n",
        "    //ALLOCATE HOST MEM\n",
        "    h_image = (unsigned char*)malloc(dszp);\n",
        "    h_result = (int*)malloc(1024*sizeof(int));    \n",
        "    \n",
        "    //ALLOCATE MEM\n",
        "    cudaMalloc(&d_image, dszp);\n",
        "    cudaMalloc(&d_result, 1024*sizeof(int));\n",
        "    cudaCheckErrors(\"cudaMalloc fail \\n\");\n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "    //FILL VALUES\n",
        "    fill_1_block <<< 1024, 1024 >>> (d_image);\n",
        "    cudaCheckErrors(\"Kernel CALL fail \\n\");\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    printf (\"Time for the filling kernel: %f ms\\n\", time);\n",
        "       \n",
        "    cudaMemcpy(h_image, d_image, dszp*sizeof(unsigned char), cudaMemcpyDeviceToHost);\n",
        "\t  cudaCheckErrors(\"Memory copying filled image fail \\n\");\n",
        "    \n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "    sum_reduce_simple <<< 1024, 1024, 1024*sizeof(int) >>> (d_image, d_result);\n",
        "    cudaCheckErrors(\"Kernel sum_reduce_simple CALL fail \\n\");\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    printf (\"Time for the sum_reduce_simple kernel: %f ms\\n\", time);\n",
        "    \n",
        "    cudaMemcpy(h_result, d_result, BLOCK*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\t  cudaCheckErrors(\"Memory copying result fail \\n\");\n",
        "    \n",
        "    \n",
        "    //FREE MEM\n",
        "    cudaFree(d_image);\n",
        "    cudaFree(d_result);\n",
        "    cudaCheckErrors(\"cudaFree fail \\n\");\n",
        "    \n",
        "    printf (\"SUM is: %d\\n\",h_result[1023]);\n",
        "    printf (\"%u, %u ... %u, %u\\n\",h_image[0], h_image[1], h_image[1024*1023+1022], h_image[1024*1023+1023]);    \n",
        "    //printf (\"All is OK \");\n",
        "    \n",
        "    free(h_image);\n",
        "    free(h_result);\n",
        "    return(0);\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Time for the filling kernel: 0.093568 ms\\nTime for the sum_reduce_simple kernel: 0.270112 ms\\nSUM is: 1024\\n1, 1 ... 1, 1\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "FA7Mz9NcfHBs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Make reduce sum for **1 GB**"
      ]
    },
    {
      "metadata": {
        "id": "3TOhngl2fEKi",
        "colab_type": "code",
        "outputId": "22290aa7-4795-43c9-e483-7d32d8a1b717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <iostream>\n",
        "#include <time.h>\n",
        "#include <fstream>\n",
        "#include <stdint.h> \n",
        "\n",
        "#define BLOCK 1024\n",
        "\n",
        "#define cudaCheckErrors(msg) \\\n",
        "    do { \\\n",
        "        cudaError_t __err = cudaGetLastError(); \\\n",
        "        if (__err != cudaSuccess) { \\\n",
        "            fprintf(stderr, \"Fatal error at runtime: %s (%s at %s:%d)\\n\", \\\n",
        "                msg, cudaGetErrorString(__err), \\\n",
        "                __FILE__, __LINE__); \\\n",
        "            fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\\n",
        "            exit(1); \\\n",
        "        } \\\n",
        "    } while (0)\n",
        "\n",
        "__global__ void fill_1_block( unsigned char *vec, int index)\n",
        "{    \n",
        "    int idx = threadIdx.x;    \n",
        "    unsigned int i = index*1024*1024 +  blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    \n",
        "    //how to make it random?\n",
        "    vec[i] = 1;    \n",
        "}\n",
        "\n",
        "__global__ void sum_reduce_simple(unsigned char *g_ivec,  int *g_ovec,  int index){\n",
        "    extern __shared__ int sdata[];\n",
        "    \n",
        "    //each thread load s one element from global to shared mem\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = index*1024*1024 + blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    sdata[tid] = g_ivec[i];\n",
        "    __syncthreads();\n",
        "\n",
        "    // do reduction in shared mem\n",
        "    for (unsigned int s=1; s <  blockDim.x ; s *= 2) {\n",
        "        if (tid % (2*s) == 0) {\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_ovec[1024*index + blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "    cudaEvent_t start, stop;\n",
        "    float time;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    \n",
        "    unsigned char *d_image, *h_image;\n",
        "    int *d_result, *h_result ;\n",
        "         \n",
        "    size_t dszp = BLOCK*1024*1024;\n",
        "    \n",
        "    //ALLOCATE HOST MEM\n",
        "    h_image = (unsigned char*)malloc(dszp);\n",
        "    h_result = (int*)malloc(1024*1024*sizeof(int));    \n",
        "    \n",
        "    //ALLOCATE MEM\n",
        "    cudaMalloc(&d_image, dszp);\n",
        "    cudaMalloc(&d_result, 1024*1024*sizeof(int));\n",
        "    cudaCheckErrors(\"cudaMalloc fail \\n\");\n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "    //FILL VALUES\n",
        "    for (int i = 0; i<1024; i++){\n",
        "        fill_1_block <<< 1024, 1024 >>> (d_image, i);\n",
        "    }\n",
        "    cudaCheckErrors(\"Kernel CALL fail \\n\");\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    printf (\"Time for the filling kernel: %f ms\\n\", time);\n",
        "       \n",
        "    cudaMemcpy(h_image, d_image, dszp*sizeof(unsigned char), cudaMemcpyDeviceToHost);\n",
        "\t  cudaCheckErrors(\"Memory copying filled image fail \\n\");\n",
        "    \n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "    for (int i = 0; i<1024; i++){\n",
        "        sum_reduce_simple <<< 1024, 1024, BLOCK*sizeof(int) >>> (d_image, d_result, i);\n",
        "    }\n",
        "    cudaCheckErrors(\"Kernel sum_reduce_simple CALL fail \\n\");\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    printf (\"Time for the sum_reduce_simple kernel: %f ms\\n\", time);\n",
        "    \n",
        "    cudaMemcpy(h_result, d_result, 1024*1024*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\t  cudaCheckErrors(\"Memory copying result fail \\n\");\n",
        "    \n",
        "    \n",
        "    //FREE MEM\n",
        "    cudaFree(d_image);\n",
        "    cudaFree(d_result);\n",
        "    cudaCheckErrors(\"cudaFree fail \\n\");\n",
        "    \n",
        "    printf (\"SUM is: %d\\n\",h_result[1024*1023 + 1023]);\n",
        "    printf (\"%u, %u ... %u, %u\\n\",h_image[0], h_image[1], h_image[1024*1024*1023+1024*1023 + 1022], h_image[1024*1024*1023+1024*1023 + 1023]);    \n",
        "    //printf (\"All is OK \");\n",
        "    \n",
        "    free(h_image);\n",
        "    free(h_result);\n",
        "    return(0);\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tcmalloc: large alloc 1073741824 bytes == 0x55a314bf0000 @  0x7f679f7891e7 0x55a3132a5983 0x7f679e7bab97 0x55a3132a580a\\nTime for the filling kernel: 20.266497 ms\\nTime for the sum_reduce_simple kernel: 220.612701 ms\\nSUM is: 1024\\n1, 1 ... 1, 1\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "metadata": {
        "id": "Y0nsDmIVi2lQ",
        "colab_type": "code",
        "outputId": "772646af-43ec-4fa2-b77d-2e8c1fb11321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <iostream>\n",
        "#include <time.h>\n",
        "#include <fstream>\n",
        "#include <stdint.h> \n",
        "\n",
        "#define BLOCK 1024\n",
        "\n",
        "#define cudaCheckErrors(msg) \\\n",
        "    do { \\\n",
        "        cudaError_t __err = cudaGetLastError(); \\\n",
        "        if (__err != cudaSuccess) { \\\n",
        "            fprintf(stderr, \"Fatal error at runtime: %s (%s at %s:%d)\\n\", \\\n",
        "                msg, cudaGetErrorString(__err), \\\n",
        "                __FILE__, __LINE__); \\\n",
        "            fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\\n",
        "            exit(1); \\\n",
        "        } \\\n",
        "    } while (0)\n",
        "\n",
        "__global__ void fill_1_block( unsigned char *vec, int index)\n",
        "{    \n",
        "    int idx = threadIdx.x;    \n",
        "    unsigned int i = index*1024*1024 +  blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    \n",
        "    //how to make it random?\n",
        "    vec[i] = 1;    \n",
        "}\n",
        "\n",
        "__global__ void sum_reduce_simple(unsigned char *g_ivec,  int *g_ovec,  int index){\n",
        "    extern __shared__ int sdata[];\n",
        "    \n",
        "    //each thread load s one element from global to shared mem\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = index*1024*1024 + blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    sdata[tid] = g_ivec[i];\n",
        "    __syncthreads();\n",
        "\n",
        "    // do reduction in shared mem\n",
        "    for (unsigned int s=1; s <  blockDim.x ; s *= 2) {\n",
        "        if (tid % (2*s) == 0) {\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_ovec[1024*index + blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "__global__ void sum_reduce_strided(unsigned char *g_ivec,  int *g_ovec,  int index){\n",
        "    extern __shared__ int sdata[];\n",
        "    \n",
        "    //each thread load s one element from global to shared mem\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = index*1024*1024 + blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    sdata[tid] = g_ivec[i];\n",
        "    __syncthreads();\n",
        "\n",
        "    // do reduction in shared mem\n",
        "    for (unsigned int s=1; s < blockDim.x; s *= 2) {  \n",
        "        int index = 2 * s * tid;\n",
        "        if (index < blockDim.x) {\n",
        "            sdata[index] += sdata[index + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_ovec[1024*index + blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "    cudaEvent_t start, stop;\n",
        "    float time;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    \n",
        "    unsigned char *d_image, *h_image;\n",
        "    int *d_result, *h_result ;\n",
        "         \n",
        "    size_t dszp = BLOCK*1024*1024;\n",
        "    \n",
        "    //ALLOCATE HOST MEM\n",
        "    h_image = (unsigned char*)malloc(dszp);\n",
        "    h_result = (int*)malloc(1024*1024*sizeof(int));    \n",
        "    \n",
        "    //ALLOCATE MEM\n",
        "    cudaMalloc(&d_image, dszp);\n",
        "    cudaMalloc(&d_result, 1024*1024*sizeof(int));\n",
        "    cudaCheckErrors(\"cudaMalloc fail \\n\");\n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "    //FILL VALUES\n",
        "    for (int i = 0; i<1024; i++){\n",
        "        fill_1_block <<< 1024, 1024 >>> (d_image, i);\n",
        "    }\n",
        "    cudaCheckErrors(\"Kernel CALL fail \\n\");\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    //printf (\"Time for the filling kernel: %f ms\\n\", time);\n",
        "       \n",
        "    cudaMemcpy(h_image, d_image, dszp*sizeof(unsigned char), cudaMemcpyDeviceToHost);\n",
        "\t  cudaCheckErrors(\"Memory copying filled image fail \\n\");\n",
        "    \n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "    for (int i = 0; i<1024; i++){\n",
        "        sum_reduce_strided <<< 1024, 1024, BLOCK*sizeof(int) >>> (d_image, d_result, i);\n",
        "    }\n",
        "    cudaCheckErrors(\"Kernel sum_reduce_strided CALL fail \\n\");\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    printf (\"Time %f ms\\n\", time);\n",
        "    \n",
        "    cudaMemcpy(h_result, d_result, 1024*1024*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\t  cudaCheckErrors(\"Memory copying result fail \\n\");\n",
        "    \n",
        "    \n",
        "    //FREE MEM\n",
        "    cudaFree(d_image);\n",
        "    cudaFree(d_result);\n",
        "    cudaCheckErrors(\"cudaFree fail \\n\");\n",
        "    \n",
        "    printf (\"SUM is: %d\\n\",h_result[1024*1023 + 1023]);\n",
        "    //printf (\"%u, %u ... %u, %u\\n\",h_image[0], h_image[1], h_image[1024*1024*1023+1024*1023 + 1022], h_image[1024*1024*1023+1024*1023 + 1023]);    \n",
        "    //printf (\"All is OK \");\n",
        "    \n",
        "    free(h_image);\n",
        "    free(h_result);\n",
        "    return(0);\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tcmalloc: large alloc 1073741824 bytes == 0x556b96f56000 @  0x7fe4bac321e7 0x556b952c6983 0x7fe4b9c63b97 0x556b952c680a\\nTime 186.648544 ms\\nSUM is: 1024\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "metadata": {
        "id": "Je9FZ7zdk8SG",
        "colab_type": "code",
        "outputId": "00519aaa-679d-424b-cf78-f6a602af45d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <iostream>\n",
        "#include <time.h>\n",
        "#include <fstream>\n",
        "#include <stdint.h> \n",
        "\n",
        "#define BLOCK 1024\n",
        "\n",
        "#define cudaCheckErrors(msg) \\\n",
        "    do { \\\n",
        "        cudaError_t __err = cudaGetLastError(); \\\n",
        "        if (__err != cudaSuccess) { \\\n",
        "            fprintf(stderr, \"Fatal error at runtime: %s (%s at %s:%d)\\n\", \\\n",
        "                msg, cudaGetErrorString(__err), \\\n",
        "                __FILE__, __LINE__); \\\n",
        "            fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\\n",
        "            exit(1); \\\n",
        "        } \\\n",
        "    } while (0)\n",
        "\n",
        "__global__ void fill_1_block( unsigned char *vec, int index)\n",
        "{    \n",
        "    int idx = threadIdx.x;    \n",
        "    unsigned int i = index*1024*1024 +  blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    \n",
        "    //how to make it random?\n",
        "    vec[i] = 1;    \n",
        "}\n",
        "\n",
        "__global__ void sum_reduce_simple(unsigned char *g_ivec,  int *g_ovec,  int index){\n",
        "    extern __shared__ int sdata[];\n",
        "    \n",
        "    //each thread load s one element from global to shared mem\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = index*1024*1024 + blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    sdata[tid] = g_ivec[i];\n",
        "    __syncthreads();\n",
        "\n",
        "    // do reduction in shared mem\n",
        "    for (unsigned int s=1; s <  blockDim.x ; s *= 2) {\n",
        "        if (tid % (2*s) == 0) {\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_ovec[1024*index + blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "__global__ void sum_reduce_strided(unsigned char *g_ivec,  int *g_ovec,  int index){\n",
        "    extern __shared__ int sdata[];\n",
        "    \n",
        "    //each thread load s one element from global to shared mem\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = index*1024*1024 + blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    sdata[tid] = g_ivec[i];\n",
        "    __syncthreads();\n",
        "\n",
        "    // do reduction in shared mem\n",
        "    for (unsigned int s=1; s < blockDim.x; s *= 2) {  \n",
        "        int index = 2 * s * tid;\n",
        "        if (index < blockDim.x) {\n",
        "            sdata[index] += sdata[index + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_ovec[1024*index + blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "__global__ void sum_reduce_reversed(unsigned char *g_ivec,  int *g_ovec,  int index){\n",
        "    extern __shared__ int sdata[];\n",
        "    \n",
        "    //each thread load s one element from global to shared mem\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = index*1024*1024 + blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    sdata[tid] = g_ivec[i];\n",
        "    __syncthreads();\n",
        "\n",
        "    // do reduction in shared mem\n",
        "    for (unsigned int s=blockDim.x/2; s>0; s>>=1) {\n",
        "        if (tid < s) {\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    \n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_ovec[1024*index + blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "    cudaEvent_t start, stop;\n",
        "    float time;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    \n",
        "    unsigned char *d_image, *h_image;\n",
        "    int *d_result, *h_result ;\n",
        "         \n",
        "    size_t dszp = BLOCK*1024*1024;\n",
        "    \n",
        "    //ALLOCATE HOST MEM\n",
        "    h_image = (unsigned char*)malloc(dszp);\n",
        "    h_result = (int*)malloc(1024*1024*sizeof(int));    \n",
        "    \n",
        "    //ALLOCATE MEM\n",
        "    cudaMalloc(&d_image, dszp);\n",
        "    cudaMalloc(&d_result, 1024*1024*sizeof(int));\n",
        "    cudaCheckErrors(\"cudaMalloc fail \\n\");\n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "    //FILL VALUES\n",
        "    for (int i = 0; i<1024; i++){\n",
        "        fill_1_block <<< 1024, 1024 >>> (d_image, i);\n",
        "    }\n",
        "    cudaCheckErrors(\"Kernel CALL fail \\n\");\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    //printf (\"Time for the filling kernel: %f ms\\n\", time);\n",
        "       \n",
        "    cudaMemcpy(h_image, d_image, dszp*sizeof(unsigned char), cudaMemcpyDeviceToHost);\n",
        "\t  cudaCheckErrors(\"Memory copying filled image fail \\n\");\n",
        "    \n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "    for (int i = 0; i<1024; i++){\n",
        "        sum_reduce_reversed <<< 1024, 1024, BLOCK*sizeof(int) >>> (d_image, d_result, i);\n",
        "    }\n",
        "    cudaCheckErrors(\"Kernel sum_reduce_reversed CALL fail \\n\");\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    printf (\"Time %f ms\\n\", time);\n",
        "    \n",
        "    cudaMemcpy(h_result, d_result, 1024*1024*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\t  cudaCheckErrors(\"Memory copying result fail \\n\");\n",
        "    \n",
        "    \n",
        "    //FREE MEM\n",
        "    cudaFree(d_image);\n",
        "    cudaFree(d_result);\n",
        "    cudaCheckErrors(\"cudaFree fail \\n\");\n",
        "    \n",
        "    printf (\"SUM is: %d\\n\",h_result[1024*1023 + 1023]);\n",
        "    //printf (\"%u, %u ... %u, %u\\n\",h_image[0], h_image[1], h_image[1024*1024*1023+1024*1023 + 1022], h_image[1024*1024*1023+1024*1023 + 1023]);    \n",
        "    //printf (\"All is OK \");\n",
        "    \n",
        "    free(h_image);\n",
        "    free(h_result);\n",
        "    return(0);\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tcmalloc: large alloc 1073741824 bytes == 0x55b2db2b2000 @  0x7f3d8697c1e7 0x55b2d80d9983 0x7f3d859adb97 0x55b2d80d980a\\nTime 159.423584 ms\\nSUM is: 1024\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "e5bukcz-mKEv",
        "colab_type": "code",
        "outputId": "d9f53de4-063e-4369-b31b-e00dead45343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <iostream>\n",
        "#include <time.h>\n",
        "#include <fstream>\n",
        "#include <stdint.h> \n",
        "\n",
        "#define BLOCK 1024\n",
        "\n",
        "#define cudaCheckErrors(msg) \\\n",
        "    do { \\\n",
        "        cudaError_t __err = cudaGetLastError(); \\\n",
        "        if (__err != cudaSuccess) { \\\n",
        "            fprintf(stderr, \"Fatal error at runtime: %s (%s at %s:%d)\\n\", \\\n",
        "                msg, cudaGetErrorString(__err), \\\n",
        "                __FILE__, __LINE__); \\\n",
        "            fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\\n",
        "            exit(1); \\\n",
        "        } \\\n",
        "    } while (0)\n",
        "\n",
        "__global__ void fill_1_block( unsigned char *vec, int index)\n",
        "{    \n",
        "    int idx = threadIdx.x;    \n",
        "    unsigned int i = index*1024*1024 +  blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    \n",
        "    //how to make it random?\n",
        "    vec[i] = 1;    \n",
        "}\n",
        "\n",
        "__global__ void sum_reduce_simple(unsigned char *g_ivec,  int *g_ovec,  int index){\n",
        "    extern __shared__ int sdata[];\n",
        "    \n",
        "    //each thread load s one element from global to shared mem\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = index*1024*1024 + blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    sdata[tid] = g_ivec[i];\n",
        "    __syncthreads();\n",
        "\n",
        "    // do reduction in shared mem\n",
        "    for (unsigned int s=1; s <  blockDim.x ; s *= 2) {\n",
        "        if (tid % (2*s) == 0) {\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_ovec[1024*index + blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "__global__ void sum_reduce_strided(unsigned char *g_ivec,  int *g_ovec,  int index){\n",
        "    extern __shared__ int sdata[];\n",
        "    \n",
        "    //each thread load s one element from global to shared mem\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = index*1024*1024 + blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    sdata[tid] = g_ivec[i];\n",
        "    __syncthreads();\n",
        "\n",
        "    // do reduction in shared mem\n",
        "    for (unsigned int s=1; s < blockDim.x; s *= 2) {  \n",
        "        int index = 2 * s * tid;\n",
        "        if (index < blockDim.x) {\n",
        "            sdata[index] += sdata[index + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_ovec[1024*index + blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "__global__ void sum_reduce_reversed(unsigned char *g_ivec,  int *g_ovec,  int index){\n",
        "    extern __shared__ int sdata[];\n",
        "    \n",
        "    //each thread load s one element from global to shared mem\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = index*1024*1024 + blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    sdata[tid] = g_ivec[i];\n",
        "    __syncthreads();\n",
        "\n",
        "    // do reduction in shared mem\n",
        "    for (unsigned int s=blockDim.x/2; s>0; s>>=1) {\n",
        "        if (tid < s) {\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    \n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_ovec[1024*index + blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "__global__ void sum_reduce_halved(unsigned char *g_ivec,  int *g_ovec,  int index){\n",
        "    extern __shared__ int sdata[];\n",
        "    \n",
        "    // perform first level of reduction,\n",
        "    // reading from global memory, writing to shared memory\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = index*1024*1024 + blockIdx.x*(blockDim.x*2) + threadIdx.x;\n",
        "    sdata[tid] = g_ivec[i] + g_ivec[i+blockDim.x];\n",
        "    __syncthreads();\n",
        "\n",
        "    // do reduction in shared mem\n",
        "    for (unsigned int s=blockDim.x/2; s>0; s>>=1) {\n",
        "        if (tid < s) {\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    \n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_ovec[1024*index + blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    cudaEvent_t start, stop;\n",
        "    float time;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    \n",
        "    unsigned char *d_image, *h_image;\n",
        "    int *d_result, *h_result ;\n",
        "         \n",
        "    size_t dszp = BLOCK*1024*1024;\n",
        "    \n",
        "    //ALLOCATE HOST MEM\n",
        "    h_image = (unsigned char*)malloc(dszp);\n",
        "    h_result = (int*)malloc(1024*1024*sizeof(int));    \n",
        "    \n",
        "    //ALLOCATE MEM\n",
        "    cudaMalloc(&d_image, dszp);\n",
        "    cudaMalloc(&d_result, 1024*1024*sizeof(int));\n",
        "    cudaCheckErrors(\"cudaMalloc fail \\n\");\n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "    //FILL VALUES\n",
        "    for (int i = 0; i<1024; i++){\n",
        "        fill_1_block <<< 1024, 1024 >>> (d_image, i);\n",
        "    }\n",
        "    cudaCheckErrors(\"Kernel CALL fail \\n\");\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    //printf (\"Time for the filling kernel: %f ms\\n\", time);\n",
        "       \n",
        "    cudaMemcpy(h_image, d_image, dszp*sizeof(unsigned char), cudaMemcpyDeviceToHost);\n",
        "\t  cudaCheckErrors(\"Memory copying filled image fail \\n\");\n",
        "    \n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "    \n",
        "    for (int i = 0; i<1024; i++){\n",
        "        sum_reduce_halved <<< 1024, 512, BLOCK*sizeof(int) >>> (d_image, d_result, i);\n",
        "    }\n",
        "    \n",
        "    cudaCheckErrors(\"Kernel sum_reduce_reversed CALL fail \\n\");\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    printf (\"Time %f ms\\n\", time);\n",
        "    \n",
        "    cudaMemcpy(h_result, d_result, 1024*1024*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\t  cudaCheckErrors(\"Memory copying result fail \\n\");\n",
        "    \n",
        "    \n",
        "    //FREE MEM\n",
        "    cudaFree(d_image);\n",
        "    cudaFree(d_result);\n",
        "    cudaCheckErrors(\"cudaFree fail \\n\");\n",
        "    \n",
        "    printf (\"SUM is: %d %d %d %d \\n\",h_result[0], h_result[1], h_result[1024*1023 + 1022], h_result[1024*1023 + 1023]);\n",
        "    //printf (\"%u, %u ... %u, %u\\n\",h_image[0], h_image[1], h_image[1024*1024*1023+1024*1023 + 1022], h_image[1024*1024*1023+1024*1023 + 1023]);    \n",
        "    //printf (\"All is OK \");\n",
        "    \n",
        "    free(h_image);\n",
        "    free(h_result);\n",
        "    return(0);\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tcmalloc: large alloc 1073741824 bytes == 0x5577cee66000 @  0x7f877286c1e7 0x5577cc247983 0x7f877189db97 0x5577cc24780a\\nTime 66.911423 ms\\nSUM is: 1024 1024 1024 1024 \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "mtwJyveWUNL9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What if we try 2048 elements?"
      ]
    },
    {
      "metadata": {
        "id": "7H-kU5mTUJnl",
        "colab_type": "code",
        "outputId": "b5b34c5d-24e7-43fa-83ff-51871003f79a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <iostream>\n",
        "#include <time.h>\n",
        "#include <fstream>\n",
        "#include <stdint.h> \n",
        "#include <time.h>\n",
        "\n",
        "#define BLOCK 1024\n",
        "\n",
        "#define cudaCheckErrors(msg) \\\n",
        "    do { \\\n",
        "        cudaError_t __err = cudaGetLastError(); \\\n",
        "        if (__err != cudaSuccess) { \\\n",
        "            fprintf(stderr, \"Fatal error at runtime: %s (%s at %s:%d)\\n\", \\\n",
        "                msg, cudaGetErrorString(__err), \\\n",
        "                __FILE__, __LINE__); \\\n",
        "            fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\\n",
        "            exit(1); \\\n",
        "        } \\\n",
        "    } while (0)\n",
        "\n",
        "__global__ void fill_1_block( unsigned char *vec, int index)\n",
        "{    \n",
        "    int idx = threadIdx.x;    \n",
        "    unsigned int i = index*1024*1024 +  blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    \n",
        "    //how to make it random?\n",
        "    vec[i] = 1;    \n",
        "}\n",
        "\n",
        "__global__ void sum_reduce_simple(unsigned char *g_ivec,  int *g_ovec,  int index){\n",
        "    extern __shared__ int sdata[];\n",
        "    \n",
        "    //each thread load s one element from global to shared mem\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = index*1024*1024 + blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    sdata[tid] = g_ivec[i];\n",
        "    __syncthreads();\n",
        "\n",
        "    // do reduction in shared mem\n",
        "    for (unsigned int s=1; s <  blockDim.x ; s *= 2) {\n",
        "        if (tid % (2*s) == 0) {\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_ovec[1024*index + blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "__global__ void sum_reduce_strided(unsigned char *g_ivec,  int *g_ovec,  int index){\n",
        "    extern __shared__ int sdata[];\n",
        "    \n",
        "    //each thread load s one element from global to shared mem\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = index*1024*1024 + blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    sdata[tid] = g_ivec[i];\n",
        "    __syncthreads();\n",
        "\n",
        "    // do reduction in shared mem\n",
        "    for (unsigned int s=1; s < blockDim.x; s *= 2) {  \n",
        "        int index = 2 * s * tid;\n",
        "        if (index < blockDim.x) {\n",
        "            sdata[index] += sdata[index + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_ovec[1024*index + blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "__global__ void sum_reduce_reversed(unsigned char *g_ivec,  int *g_ovec,  int index){\n",
        "    extern __shared__ int sdata[];\n",
        "    \n",
        "    //each thread load s one element from global to shared mem\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = index*1024*1024 + blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    sdata[tid] = g_ivec[i];\n",
        "    __syncthreads();\n",
        "\n",
        "    // do reduction in shared mem\n",
        "    for (unsigned int s=blockDim.x/2; s>0; s>>=1) {\n",
        "        if (tid < s) {\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    \n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_ovec[1024*index + blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "__global__ void sum_reduce_halved(unsigned char *g_ivec,  int *g_ovec){\n",
        "    extern __shared__ int sdata[];\n",
        "    \n",
        "    // perform first level of reduction,\n",
        "    // reading from global memory, writing to shared memory\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = blockIdx.x*(blockDim.x*2) + threadIdx.x;\n",
        "    sdata[tid] = g_ivec[i] + g_ivec[i+blockDim.x];\n",
        "    __syncthreads();\n",
        "\n",
        "    // do reduction in shared mem\n",
        "    for (unsigned int s=blockDim.x/2; s>0; s>>=1) {\n",
        "        if (tid < s) {\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    \n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_ovec[blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    cudaEvent_t start, stop;\n",
        "    float time;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    \n",
        "    unsigned char *d_image, *h_image;\n",
        "    int *d_result, *h_result ;\n",
        "         \n",
        "    size_t dszp = BLOCK*1024*1024;\n",
        "    \n",
        "    //ALLOCATE HOST MEM\n",
        "    h_image = (unsigned char*)malloc(dszp);\n",
        "    h_result = (int*)malloc(1024*1024*sizeof(int));    \n",
        "    \n",
        "    //ALLOCATE MEM\n",
        "    cudaMalloc(&d_image, dszp);\n",
        "    cudaMalloc(&d_result, 1024*1024*sizeof(int));\n",
        "    cudaCheckErrors(\"cudaMalloc fail \\n\");\n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "    //FILL VALUES\n",
        "    for (int i = 0; i<1024; i++){\n",
        "        fill_1_block <<< 1024, 1024 >>> (d_image, i);\n",
        "    }\n",
        "    cudaCheckErrors(\"Kernel CALL fail \\n\");\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    //printf (\"Time for the filling kernel: %f ms\\n\", time);\n",
        "       \n",
        "    cudaMemcpy(h_image, d_image, dszp*sizeof(unsigned char), cudaMemcpyDeviceToHost);\n",
        "\t  cudaCheckErrors(\"Memory copying filled image fail \\n\");\n",
        "    \n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "    \n",
        "    sum_reduce_halved <<< 1024*1024, 512, 1024*sizeof(int) >>> (d_image, d_result);\n",
        "    \n",
        "    cudaCheckErrors(\"Kernel sum_reduce_reversed CALL fail \\n\");\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    printf (\"Time %f ms\\n\", time);\n",
        "    \n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    cudaMemcpy(h_result, d_result, 1024*1024*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\t  cudaCheckErrors(\"Memory copying result fail \\n\");\n",
        "    \n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    printf (\"Copy Time %f ms\\n\", time);\n",
        "    \n",
        "    //FREE MEM\n",
        "    cudaFree(d_image);\n",
        "    cudaFree(d_result);\n",
        "    cudaCheckErrors(\"cudaFree fail \\n\");\n",
        "    \n",
        "    printf (\"SUM is: %d %d %d %d \\n\",h_result[0], h_result[1], h_result[1024*1023 + 1022], h_result[1024*1023 + 1023]);\n",
        "    //printf (\"%u, %u ... %u, %u\\n\",h_image[0], h_image[1], h_image[1024*1024*1023+1024*1023 + 1022], h_image[1024*1024*1023+1024*1023 + 1023]);    \n",
        "    //printf (\"All is OK \");\n",
        "      \n",
        "    free(h_image);\n",
        "    free(h_result);\n",
        "    return(0);\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tcmalloc: large alloc 1073741824 bytes == 0x562ea6748000 @  0x7f2063cd01e7 0x562ea4e9e983 0x7f2062d01b97 0x562ea4e9e80a\\nTime 61.568993 ms\\nCopy Time 4.592576 ms\\nSUM is: 1024 1024 1024 1024 \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "metadata": {
        "id": "wiCvo1NfcAE7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1024 threads"
      ]
    },
    {
      "metadata": {
        "id": "lNerrQrsb_jd",
        "colab_type": "code",
        "outputId": "5ff780be-07f0-4ca4-ae85-71525c0c946f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <iostream>\n",
        "#include <time.h>\n",
        "#include <fstream>\n",
        "#include <stdint.h> \n",
        "#include <time.h>\n",
        "\n",
        "#define BLOCK 1024\n",
        "\n",
        "#define cudaCheckErrors(msg) \\\n",
        "    do { \\\n",
        "        cudaError_t __err = cudaGetLastError(); \\\n",
        "        if (__err != cudaSuccess) { \\\n",
        "            fprintf(stderr, \"Fatal error at runtime: %s (%s at %s:%d)\\n\", \\\n",
        "                msg, cudaGetErrorString(__err), \\\n",
        "                __FILE__, __LINE__); \\\n",
        "            fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\\n",
        "            exit(1); \\\n",
        "        } \\\n",
        "    } while (0)\n",
        "\n",
        "__global__ void fill_1_block( unsigned char *vec, int index)\n",
        "{    \n",
        "    int idx = threadIdx.x;    \n",
        "    unsigned int i = index*1024*1024 +  blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    \n",
        "    //how to make it random?\n",
        "    vec[i] = 1;    \n",
        "}\n",
        "\n",
        "__global__ void sum_reduce_simple(unsigned char *g_ivec,  int *g_ovec,  int index){\n",
        "    extern __shared__ int sdata[];\n",
        "    \n",
        "    //each thread load s one element from global to shared mem\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = index*1024*1024 + blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    sdata[tid] = g_ivec[i];\n",
        "    __syncthreads();\n",
        "\n",
        "    // do reduction in shared mem\n",
        "    for (unsigned int s=1; s <  blockDim.x ; s *= 2) {\n",
        "        if (tid % (2*s) == 0) {\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_ovec[1024*index + blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "__global__ void sum_reduce_strided(unsigned char *g_ivec,  int *g_ovec,  int index){\n",
        "    extern __shared__ int sdata[];\n",
        "    \n",
        "    //each thread load s one element from global to shared mem\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = index*1024*1024 + blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    sdata[tid] = g_ivec[i];\n",
        "    __syncthreads();\n",
        "\n",
        "    // do reduction in shared mem\n",
        "    for (unsigned int s=1; s < blockDim.x; s *= 2) {  \n",
        "        int index = 2 * s * tid;\n",
        "        if (index < blockDim.x) {\n",
        "            sdata[index] += sdata[index + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_ovec[1024*index + blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "__global__ void sum_reduce_reversed(unsigned char *g_ivec,  int *g_ovec,  int index){\n",
        "    extern __shared__ int sdata[];\n",
        "    \n",
        "    //each thread load s one element from global to shared mem\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = index*1024*1024 + blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    sdata[tid] = g_ivec[i];\n",
        "    __syncthreads();\n",
        "\n",
        "    // do reduction in shared mem\n",
        "    for (unsigned int s=blockDim.x/2; s>0; s>>=1) {\n",
        "        if (tid < s) {\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    \n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_ovec[1024*index + blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "__global__ void sum_reduce_halved(unsigned char *g_ivec,  int *g_ovec){\n",
        "    extern __shared__ int sdata[];\n",
        "    \n",
        "    // perform first level of reduction,\n",
        "    // reading from global memory, writing to shared memory\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = blockIdx.x*(blockDim.x*2) + threadIdx.x;\n",
        "    sdata[tid] = g_ivec[i] + g_ivec[i+blockDim.x];\n",
        "    __syncthreads();\n",
        "\n",
        "    // do reduction in shared mem\n",
        "    for (unsigned int s=blockDim.x/2; s>0; s>>=1) {\n",
        "        if (tid < s) {\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    \n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_ovec[blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    cudaEvent_t start, stop;\n",
        "    float time;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    \n",
        "    unsigned char *d_image, *h_image;\n",
        "    int *d_result, *h_result ;\n",
        "         \n",
        "    size_t dszp = BLOCK*1024*1024;\n",
        "    \n",
        "    //ALLOCATE HOST MEM\n",
        "    h_image = (unsigned char*)malloc(dszp);\n",
        "    h_result = (int*)malloc(2*1024*1024*sizeof(int));    \n",
        "    \n",
        "    //ALLOCATE MEM\n",
        "    cudaMalloc(&d_image, dszp);\n",
        "    cudaMalloc(&d_result, 2*1024*1024*sizeof(int));\n",
        "    cudaCheckErrors(\"cudaMalloc fail \\n\");\n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "    //FILL VALUES\n",
        "    for (int i = 0; i<1024; i++){\n",
        "        fill_1_block <<< 1024, 1024 >>> (d_image, i);\n",
        "    }\n",
        "    cudaCheckErrors(\"Kernel CALL fail \\n\");\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    //printf (\"Time for the filling kernel: %f ms\\n\", time);\n",
        "       \n",
        "    cudaMemcpy(h_image, d_image, dszp*sizeof(unsigned char), cudaMemcpyDeviceToHost);\n",
        "\t  cudaCheckErrors(\"Memory copying filled image fail \\n\");\n",
        "    \n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "    \n",
        "    sum_reduce_halved <<< 1024*2048, 256, 512*sizeof(int) >>> (d_image, d_result);\n",
        "    \n",
        "    cudaCheckErrors(\"Kernel sum_reduce_reversed CALL fail \\n\");\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    printf (\"Time %f ms\\n\", time);\n",
        "    \n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    cudaMemcpy(h_result, d_result, 2*1024*1024*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\t  cudaCheckErrors(\"Memory copying result fail \\n\");\n",
        "    \n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    printf (\"Copy Time %f ms\\n\", time);\n",
        "    \n",
        "    //FREE MEM\n",
        "    cudaFree(d_image);\n",
        "    cudaFree(d_result);\n",
        "    cudaCheckErrors(\"cudaFree fail \\n\");\n",
        "    \n",
        "    printf (\"SUM is: %d %d %d %d \\n\",h_result[0], h_result[1], h_result[1024*1023 + 1022], h_result[1024*1023 + 1023]);\n",
        "    //printf (\"%u, %u ... %u, %u\\n\",h_image[0], h_image[1], h_image[1024*1024*1023+1024*1023 + 1022], h_image[1024*1024*1023+1024*1023 + 1023]);    \n",
        "    //printf (\"All is OK \");\n",
        "      \n",
        "    free(h_image);\n",
        "    free(h_result);\n",
        "    return(0);\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tcmalloc: large alloc 1073741824 bytes == 0x55bbc25c4000 @  0x7fd6158a51e7 0x55bbbf9da983 0x7fd6148d6b97 0x55bbbf9da80a\\nTime 52.240417 ms\\nCopy Time 9.429088 ms\\nSUM is: 512 512 512 512 \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "metadata": {
        "id": "GEelmj5fXpSL",
        "colab_type": "code",
        "outputId": "51930d7b-026d-4218-c34d-0dd0ed09776b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <iostream>\n",
        "#include <time.h>\n",
        "#include <fstream>\n",
        "#include <stdint.h> \n",
        "#include <time.h>\n",
        "\n",
        "#define BLOCK 1024\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "    \n",
        "    unsigned char *d_image, *h_image;\n",
        "    int *d_result, *h_result ;\n",
        "         \n",
        "    size_t dszp = BLOCK*1024*1024;\n",
        "    \n",
        "    //ALLOCATE HOST MEM\n",
        "    h_image = (unsigned char*)malloc(dszp);\n",
        "    h_result = (int*)malloc(1024*1024*sizeof(int));    \n",
        "    //DO it with MEMSET faster\n",
        "    for (int i = 0; i<1024*1024*1024; i++){\n",
        "        h_image[i] = 1;\n",
        "    }\n",
        "    \n",
        "    //measure time for cpu calc.\n",
        "    clock_t t1, t2;\n",
        "    \n",
        "\t  t1 = clock();\n",
        "    h_result[0] = 0;\n",
        "    for (int i = 0; i<1024*1024*1024; i++){\n",
        "        h_result[0] = h_result[0] + h_image[i];\n",
        "    }\n",
        "    \n",
        "    t2 = clock();\n",
        "    double time_taken  = ((double)(t2 - t1) / CLOCKS_PER_SEC *1000);\n",
        "    \n",
        "    printf(\"%.3f\", time_taken);\n",
        "    \n",
        "    free(h_image);\n",
        "    free(h_result);\n",
        "    return(0);\n",
        "}\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tcmalloc: large alloc 1073741824 bytes == 0x5654140e6000 @  0x7f3468fab1e7 0x565412b057c8 0x7f34681f4b97 0x565412b0567a\\n3351.780'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "metadata": {
        "id": "ED1pXrValh9D",
        "colab_type": "code",
        "outputId": "e752b2c9-0109-4ac4-f67a-aa5d021caed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <iostream>\n",
        "#include <time.h>\n",
        "#include <fstream>\n",
        "#include <stdint.h> \n",
        "#include <time.h>\n",
        "\n",
        "#define BLOCK 1024\n",
        "\n",
        "#define cudaCheckErrors(msg) \\\n",
        "    do { \\\n",
        "        cudaError_t __err = cudaGetLastError(); \\\n",
        "        if (__err != cudaSuccess) { \\\n",
        "            fprintf(stderr, \"Fatal error at runtime: %s (%s at %s:%d)\\n\", \\\n",
        "                msg, cudaGetErrorString(__err), \\\n",
        "                __FILE__, __LINE__); \\\n",
        "            fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\\n",
        "            exit(1); \\\n",
        "        } \\\n",
        "    } while (0)\n",
        "\n",
        "__global__ void fill_1_block( unsigned char *vec, int index)\n",
        "{    \n",
        "    int idx = threadIdx.x;    \n",
        "    unsigned int i = index*1024*1024 +  blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    \n",
        "    //how to make it random?\n",
        "    vec[i] = 1;    \n",
        "}\n",
        "\n",
        "__device__ void warpReduce(volatile int* sdata, int tid) {\n",
        "    sdata[tid] += sdata[tid + 32];\n",
        "    sdata[tid] += sdata[tid + 16];\n",
        "    sdata[tid] += sdata[tid + 8];\n",
        "    sdata[tid] += sdata[tid + 4];\n",
        "    sdata[tid] += sdata[tid + 2];\n",
        "    sdata[tid] += sdata[tid + 1];\n",
        "}\n",
        "\n",
        "__global__ void sum_reduce_halved(unsigned char *g_ivec,  int *g_ovec,  int index){\n",
        "    extern __shared__ int sdata[];\n",
        "    \n",
        "    // perform first level of reduction,\n",
        "    // reading from global memory, writing to shared memory\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = index*1024*1024 + blockIdx.x*(blockDim.x*2) + threadIdx.x;\n",
        "    sdata[tid] = g_ivec[i] + g_ivec[i+blockDim.x];\n",
        "    __syncthreads();\n",
        "\n",
        "    for (unsigned int s=blockDim.x/2; s>32; s>>=1) {\n",
        "        if (tid < s)\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (tid < 32) warpReduce(sdata, tid);\n",
        "    \n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_ovec[1024*index + blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    cudaEvent_t start, stop;\n",
        "    float time;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    \n",
        "    unsigned char *d_image, *h_image;\n",
        "    int *d_result, *h_result ;\n",
        "         \n",
        "    size_t dszp = BLOCK*1024*1024;\n",
        "    \n",
        "    //ALLOCATE HOST MEM\n",
        "    h_image = (unsigned char*)malloc(dszp);\n",
        "    h_result = (int*)malloc(1024*1024*sizeof(int));    \n",
        "    \n",
        "    //ALLOCATE MEM\n",
        "    cudaMalloc(&d_image, dszp);\n",
        "    cudaMalloc(&d_result, 1024*1024*sizeof(int));\n",
        "    cudaCheckErrors(\"cudaMalloc fail \\n\");\n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "    //FILL VALUES\n",
        "    for (int i = 0; i<1024; i++){\n",
        "        fill_1_block <<< 1024, 1024 >>> (d_image, i);\n",
        "    }\n",
        "    cudaCheckErrors(\"Kernel CALL fail \\n\");\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    //printf (\"Time for the filling kernel: %f ms\\n\", time);\n",
        "       \n",
        "    cudaMemcpy(h_image, d_image, dszp*sizeof(unsigned char), cudaMemcpyDeviceToHost);\n",
        "\t  cudaCheckErrors(\"Memory copying filled image fail \\n\");\n",
        "    \n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "    \n",
        "    sum_reduce_halved <<< 1024*1024, 512, BLOCK*sizeof(int) >>> (d_image, d_result, 0);\n",
        "    \n",
        "    cudaCheckErrors(\"Kernel sum_reduce_reversed CALL fail \\n\");\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    printf (\"Time %f ms\\n\", time);\n",
        "    \n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    cudaMemcpy(h_result, d_result, 1024*1024*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\t  cudaCheckErrors(\"Memory copying result fail \\n\");\n",
        "    \n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    printf (\"Copy Time %f ms\\n\", time);\n",
        "    \n",
        "    //FREE MEM\n",
        "    cudaFree(d_image);\n",
        "    cudaFree(d_result);\n",
        "    cudaCheckErrors(\"cudaFree fail \\n\");\n",
        "    \n",
        "    printf (\"SUM is: %d %d %d %d \\n\",h_result[0], h_result[1], h_result[1024*1023 + 1022], h_result[1024*1023 + 1023]);\n",
        "    //printf (\"%u, %u ... %u, %u\\n\",h_image[0], h_image[1], h_image[1024*1024*1023+1024*1023 + 1022], h_image[1024*1024*1023+1024*1023 + 1023]);    \n",
        "    //printf (\"All is OK \");\n",
        "      \n",
        "    free(h_image);\n",
        "    free(h_result);\n",
        "    return(0);\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tcmalloc: large alloc 1073741824 bytes == 0x55addf140000 @  0x7f4631a9e1e7 0x55addd7549a3 0x7f4630acfb97 0x55addd75480a\\nTime 38.478912 ms\\nCopy Time 4.597088 ms\\nSUM is: 1024 1024 1024 1024 \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "YPo7bZCooEne",
        "colab_type": "code",
        "outputId": "3a58b77a-7f77-44b6-aec9-536f2fab55a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <iostream>\n",
        "#include <time.h>\n",
        "#include <fstream>\n",
        "#include <stdint.h> \n",
        "#include <time.h>\n",
        "\n",
        "#define BLOCK 1024\n",
        "\n",
        "#define cudaCheckErrors(msg) \\\n",
        "    do { \\\n",
        "        cudaError_t __err = cudaGetLastError(); \\\n",
        "        if (__err != cudaSuccess) { \\\n",
        "            fprintf(stderr, \"Fatal error at runtime: %s (%s at %s:%d)\\n\", \\\n",
        "                msg, cudaGetErrorString(__err), \\\n",
        "                __FILE__, __LINE__); \\\n",
        "            fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\\n",
        "            exit(1); \\\n",
        "        } \\\n",
        "    } while (0)\n",
        "\n",
        "__global__ void fill_1_block( unsigned char *vec, int index)\n",
        "{    \n",
        "    unsigned int i = index*1024*1024 +  blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    \n",
        "    //how to make it random?\n",
        "    vec[i] = 1;    \n",
        "}\n",
        "\n",
        "\n",
        "template <unsigned int blockSize>\n",
        "__device__ void warpReduce(volatile int* sdata, int tid) {\n",
        "if (blockSize >= 64) sdata[tid] += sdata[tid + 32];\n",
        "if (blockSize >= 32) sdata[tid] += sdata[tid + 16];\n",
        "if (blockSize >= 16) sdata[tid] += sdata[tid + 8];\n",
        "if (blockSize >= 8) sdata[tid] += sdata[tid + 4];\n",
        "if (blockSize >= 4) sdata[tid] += sdata[tid + 2];\n",
        "if (blockSize >= 2) sdata[tid] += sdata[tid + 1];\n",
        "}\n",
        "\n",
        "template <unsigned int blockSize>\n",
        "__global__ void reduce5(unsigned char *g_ivec,  int *g_ovec){\n",
        "    extern __shared__ int sdata[];\n",
        "    \n",
        "    // perform first level of reduction,\n",
        "    // reading from global memory, writing to shared memory\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = blockIdx.x*(blockDim.x*2) + threadIdx.x;\n",
        "    sdata[tid] = g_ivec[i] + g_ivec[i+blockDim.x];\n",
        "    __syncthreads();\n",
        "\n",
        "    \n",
        "    if (blockSize >= 512) {\n",
        "       if (tid < 256) { sdata[tid] += sdata[tid + 256]; } __syncthreads(); }\n",
        "    if (blockSize >= 256) {\n",
        "       if (tid < 128) { sdata[tid] += sdata[tid + 128]; } __syncthreads(); }\n",
        "    if (blockSize >= 128) {\n",
        "       if (tid < 64) { sdata[tid] += sdata[tid + 64]; } __syncthreads(); }\n",
        "    if (tid < 32) warpReduce<blockSize>(sdata, tid);\n",
        "    \n",
        "    \n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_ovec[blockIdx.x] = sdata[0];\n",
        "}    \n",
        "\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "    cudaEvent_t start, stop;\n",
        "    float time;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    \n",
        "    unsigned char *d_image, *h_image;\n",
        "    int *d_result, *h_result ;\n",
        "         \n",
        "    size_t dszp = BLOCK*1024*1024;\n",
        "    \n",
        "    //ALLOCATE HOST MEM\n",
        "    h_image = (unsigned char*)malloc(dszp);\n",
        "    h_result = (int*)malloc(1024*1024*sizeof(int));    \n",
        "    \n",
        "    //ALLOCATE MEM\n",
        "    cudaMalloc(&d_image, dszp);\n",
        "    cudaMalloc(&d_result, 1024*1024*sizeof(int));\n",
        "    cudaCheckErrors(\"cudaMalloc fail \\n\");\n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "    //FILL VALUES\n",
        "    for (int i = 0; i<1024; i++){\n",
        "        fill_1_block <<< 1024, 1024 >>> (d_image, i);\n",
        "    }\n",
        "    cudaCheckErrors(\"Kernel CALL fail \\n\");\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    //printf (\"Time for the filling kernel: %f ms\\n\", time);\n",
        "       \n",
        "    cudaMemcpy(h_image, d_image, dszp*sizeof(unsigned char), cudaMemcpyDeviceToHost);\n",
        "\t  cudaCheckErrors(\"Memory copying filled image fail \\n\");\n",
        "    \n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "    \n",
        "    reduce5<512> <<< 1024*1024, 512, BLOCK*sizeof(int) >>> (d_image, d_result);\n",
        "    \n",
        "    cudaCheckErrors(\"Kernel sum_reduce_reversed CALL fail \\n\");\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    printf (\"Time %f ms\\n\", time);\n",
        "    \n",
        "    \n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    cudaMemcpy(h_result, d_result, 1024*1024*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\t  cudaCheckErrors(\"Memory copying result fail \\n\");\n",
        "    \n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    printf (\"Copy Time %f ms\\n\", time);\n",
        "    \n",
        "    //FREE MEM\n",
        "    cudaFree(d_image);\n",
        "    cudaFree(d_result);\n",
        "    cudaCheckErrors(\"cudaFree fail \\n\");\n",
        "    \n",
        "    printf (\"SUM is: %d %d %d %d \\n\",h_result[0], h_result[1], h_result[1024*1023 + 1022], h_result[1024*1023 + 1023]);\n",
        "    //printf (\"%u, %u ... %u, %u\\n\",h_image[0], h_image[1], h_image[1024*1024*1023+1024*1023 + 1022], h_image[1024*1024*1023+1024*1023 + 1023]);    \n",
        "    //printf (\"All is OK \");\n",
        "      \n",
        "    free(h_image);\n",
        "    free(h_result);\n",
        "    return(0);\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tcmalloc: large alloc 1073741824 bytes == 0x561845dac000 @  0x7f3f9b9001e7 0x5618438b1983 0x7f3f9a931b97 0x5618438b180a\\nTime 34.386433 ms\\nCopy Time 4.799104 ms\\nSUM is: 1024 1024 1024 1024 \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "metadata": {
        "id": "jJcUZBtxvr9L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Use:\n",
        "\n",
        "http://developer.download.nvidia.com/compute/cuda/3_2_prod/toolkit/docs/CUDA_C_Best_Practices_Guide.pdf\n",
        "\n",
        "http://vuduc.org/teaching/cse6230-hpcta-fa12/slides/cse6230-fa12--05b-reduction-notes.pdf\n"
      ]
    }
  ]
}